{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from numbers import Number\n",
    "from time import time\n",
    "from ta import momentum as mo\n",
    "from ta import volume as vo\n",
    "from ta import trend as tr\n",
    "from numpy.random import seed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, Activation, Flatten, GRU, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "# seed(1)\n",
    "# tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 31536000\n",
    "period1 = round(time() - (year * 5))\n",
    "period2 = round(time())\n",
    "asset = 'qdel'\n",
    "\n",
    "hist_data = pd.read_csv(\n",
    "    f'https://query1.finance.yahoo.com/v7/finance/download/{asset}?period1={period1}&period2={period2}&interval=1d&events=history&includeAdjustedClose=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC de Y em relação a X\n",
    "def change(x, y):\n",
    "    if len(x) == len(y):\n",
    "        change_arr = []\n",
    "        for i in range(0, len(x)):\n",
    "            if isinstance(x[i], Number) and isinstance(y[i], Number):\n",
    "                change_arr.append(((y[i] - x[i]) / x[i]) * 100)\n",
    "            else:\n",
    "                change_arr.append('NaN')\n",
    "\n",
    "        return change_arr\n",
    "    else:\n",
    "        print(f\"Error: x length {len(x)}, y length {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc</th>\n",
       "      <th>rsi</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_diff</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>tsi</th>\n",
       "      <th>tsi_signal</th>\n",
       "      <th>roc_ema_w8_ema_w20</th>\n",
       "      <th>roc_sma_w13_sma_w25</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.938226</td>\n",
       "      <td>58.789981</td>\n",
       "      <td>0.360335</td>\n",
       "      <td>-0.012137</td>\n",
       "      <td>0.372472</td>\n",
       "      <td>11.821174</td>\n",
       "      <td>11.903428</td>\n",
       "      <td>1.400998</td>\n",
       "      <td>2.125317</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.902135</td>\n",
       "      <td>56.673748</td>\n",
       "      <td>0.350624</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>0.368103</td>\n",
       "      <td>11.817746</td>\n",
       "      <td>11.891187</td>\n",
       "      <td>1.333074</td>\n",
       "      <td>1.336719</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.607240</td>\n",
       "      <td>52.011209</td>\n",
       "      <td>0.309504</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.356383</td>\n",
       "      <td>10.511356</td>\n",
       "      <td>11.694069</td>\n",
       "      <td>1.048557</td>\n",
       "      <td>0.393053</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.864073</td>\n",
       "      <td>50.207805</td>\n",
       "      <td>0.261795</td>\n",
       "      <td>-0.075671</td>\n",
       "      <td>0.337465</td>\n",
       "      <td>8.919609</td>\n",
       "      <td>11.297717</td>\n",
       "      <td>0.741426</td>\n",
       "      <td>-0.118466</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.774867</td>\n",
       "      <td>38.733700</td>\n",
       "      <td>0.126503</td>\n",
       "      <td>-0.168769</td>\n",
       "      <td>0.295273</td>\n",
       "      <td>3.573473</td>\n",
       "      <td>10.194254</td>\n",
       "      <td>-0.168199</td>\n",
       "      <td>-0.598476</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>-1.911143</td>\n",
       "      <td>39.177892</td>\n",
       "      <td>-1.095657</td>\n",
       "      <td>-2.946468</td>\n",
       "      <td>1.850811</td>\n",
       "      <td>-3.525519</td>\n",
       "      <td>10.601664</td>\n",
       "      <td>-2.786292</td>\n",
       "      <td>-0.136326</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2.478571</td>\n",
       "      <td>39.961439</td>\n",
       "      <td>-1.717034</td>\n",
       "      <td>-2.854276</td>\n",
       "      <td>1.137242</td>\n",
       "      <td>-5.952244</td>\n",
       "      <td>8.236820</td>\n",
       "      <td>-3.175945</td>\n",
       "      <td>-1.501639</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1.688351</td>\n",
       "      <td>37.734455</td>\n",
       "      <td>-2.398089</td>\n",
       "      <td>-2.828265</td>\n",
       "      <td>0.430176</td>\n",
       "      <td>-8.666748</td>\n",
       "      <td>5.822025</td>\n",
       "      <td>-3.662141</td>\n",
       "      <td>-2.905678</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>-2.106705</td>\n",
       "      <td>34.818330</td>\n",
       "      <td>-3.202699</td>\n",
       "      <td>-2.906300</td>\n",
       "      <td>-0.296399</td>\n",
       "      <td>-11.884818</td>\n",
       "      <td>3.292476</td>\n",
       "      <td>-4.322194</td>\n",
       "      <td>-4.321340</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>-5.091115</td>\n",
       "      <td>40.679306</td>\n",
       "      <td>-3.442405</td>\n",
       "      <td>-2.516805</td>\n",
       "      <td>-0.925601</td>\n",
       "      <td>-12.992330</td>\n",
       "      <td>0.966075</td>\n",
       "      <td>-4.252319</td>\n",
       "      <td>-5.446485</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1181 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            roc        rsi      macd  macd_diff  macd_signal        tsi  \\\n",
       "0     21.938226  58.789981  0.360335  -0.012137     0.372472  11.821174   \n",
       "1     15.902135  56.673748  0.350624  -0.017479     0.368103  11.817746   \n",
       "2     15.607240  52.011209  0.309504  -0.046879     0.356383  10.511356   \n",
       "3      7.864073  50.207805  0.261795  -0.075671     0.337465   8.919609   \n",
       "4     -1.774867  38.733700  0.126503  -0.168769     0.295273   3.573473   \n",
       "...         ...        ...       ...        ...          ...        ...   \n",
       "1176  -1.911143  39.177892 -1.095657  -2.946468     1.850811  -3.525519   \n",
       "1177   2.478571  39.961439 -1.717034  -2.854276     1.137242  -5.952244   \n",
       "1178   1.688351  37.734455 -2.398089  -2.828265     0.430176  -8.666748   \n",
       "1179  -2.106705  34.818330 -3.202699  -2.906300    -0.296399 -11.884818   \n",
       "1180  -5.091115  40.679306 -3.442405  -2.516805    -0.925601 -12.992330   \n",
       "\n",
       "      tsi_signal  roc_ema_w8_ema_w20  roc_sma_w13_sma_w25 trend  \n",
       "0      11.903428            1.400998             2.125317   LOW  \n",
       "1      11.891187            1.333074             1.336719   LOW  \n",
       "2      11.694069            1.048557             0.393053   LOW  \n",
       "3      11.297717            0.741426            -0.118466   LOW  \n",
       "4      10.194254           -0.168199            -0.598476   LOW  \n",
       "...          ...                 ...                  ...   ...  \n",
       "1176   10.601664           -2.786292            -0.136326  HIGH  \n",
       "1177    8.236820           -3.175945            -1.501639  HIGH  \n",
       "1178    5.822025           -3.662141            -2.905678  HIGH  \n",
       "1179    3.292476           -4.322194            -4.321340  HIGH  \n",
       "1180    0.966075           -4.252319            -5.446485  HIGH  \n",
       "\n",
       "[1181 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(change([1, 2],[2, 1])) # [100.0, -50.0] Yn > Xn se valor positivo\n",
    "trend_window = 26\n",
    "slice_start = 50\n",
    "slice_plus = 0\n",
    "\n",
    "roc = mo.roc(hist_data['Close'], window=25)\n",
    "rsi = mo.rsi(hist_data['Close'])\n",
    "stochrsi = mo.stochrsi(hist_data['Close'])\n",
    "stochrsi_d = mo.stochrsi_d(hist_data['Close'])\n",
    "stochrsi_k = mo.stochrsi_k(hist_data['Close'])\n",
    "\n",
    "tsi = mo.tsi(hist_data['Close'])\n",
    "tsi_signal = tr.ema_indicator(tsi, window=13)\n",
    "\n",
    "macd = tr.macd(hist_data['Close'])\n",
    "macd_diff = tr.macd_diff(hist_data['Close'])\n",
    "macd_signal = tr.macd_signal(hist_data['Close'])\n",
    "\n",
    "stoch = mo.stoch(hist_data['High'], hist_data['Low'], hist_data['Close'])\n",
    "ema_w8 = tr.ema_indicator(hist_data['Close'], window=8)\n",
    "ema_w20 = tr.ema_indicator(hist_data['Close'], window=20)\n",
    "\n",
    "sma_w13 = tr.sma_indicator(hist_data['Close'], window=13)\n",
    "sma_w25 = tr.sma_indicator(hist_data['Close'], window=25)\n",
    "\n",
    "roc_close_ema_w8 = change(ema_w8, hist_data['Close'])\n",
    "roc_ema_w8_ema_w20 = change(ema_w20, ema_w8)\n",
    "roc_close_ema_w20 = change(ema_w20, hist_data['Close'])\n",
    "roc_close_open = change(hist_data['Open'], hist_data['Close'])\n",
    "\n",
    "roc_close_sma_w13 = change(sma_w13, hist_data['Close'])\n",
    "roc_sma_w13_sma_w25 = change(sma_w25, sma_w13)\n",
    "roc_close_sma_w25 = change(sma_w25, hist_data['Close'])\n",
    "\n",
    "trend = mo.roc(hist_data['Close'], window=trend_window).map(lambda n : 'HIGH' if n > 0 else 'LOW')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "#     'close': np.array(list(hist_data['Close'][slice_start:-(trend_window + slice_plus)])),\n",
    "    'roc': np.array(list(roc[slice_start:-(trend_window + slice_plus)])),\n",
    "    'rsi': np.array(list(rsi[slice_start:-(trend_window + slice_plus)])),\n",
    "    # 'stoch': np.array(list(stoch[slice_start:-(trend_window + slice_plus)])),\n",
    "    # 'stochrsi': np.array(list(stochrsi[slice_start:-(trend_window + slice_plus)])),\n",
    "    # 'stochrsi_d': np.array(list(stochrsi_d[slice_start:-(trend_window + slice_plus)])),\n",
    "    # 'stochrsi_k': np.array(list(stochrsi_k[slice_start:-(trend_window + slice_plus)])),\n",
    "    'macd': np.array(list(macd[slice_start:-(trend_window + slice_plus)])),\n",
    "    'macd_diff': np.array(list(macd_diff[slice_start:-(trend_window + slice_plus)])),\n",
    "    'macd_signal': np.array(list(macd_signal[slice_start:-(trend_window + slice_plus)])),\n",
    "    'tsi': np.array(list(tsi[slice_start:-(trend_window + slice_plus)])),\n",
    "    'tsi_signal': np.array(list(tsi_signal[slice_start:-(trend_window + slice_plus)])),\n",
    "#     'ema_w8': np.array(list(ema_w8[slice_start:-(trend_window + slice_plus)])),\n",
    "#     'ema_w20': np.array(list(ema_w20[slice_start:-(trend_window + slice_plus)])),\n",
    "    'roc_close_ema_w8': np.array(list(roc_close_ema_w8[slice_start:-(trend_window + slice_plus)])),\n",
    "    'roc_ema_w8_ema_w20': np.array(list(roc_ema_w8_ema_w20[slice_start:-(trend_window + slice_plus)])),\n",
    "#     'roc_close_ema_w20': np.array(list(roc_close_ema_w20[slice_start:-(trend_window + slice_plus)])),\n",
    "\n",
    "    'roc_close_sma_w13': np.array(list(roc_close_sma_w13[slice_start:-(trend_window + slice_plus)])),\n",
    "    'roc_sma_w13_sma_w25': np.array(list(roc_sma_w13_sma_w25[slice_start:-(trend_window + slice_plus)])),\n",
    "#     'roc_close_sma_w25': np.array(list(roc_close_sma_w25[slice_start:-(trend_window + slice_plus)])),\n",
    "    'trend': np.array(list(trend[(slice_start + trend_window)::]))\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1081, 9, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df.iloc[:,0:-1].values[0:-100]\n",
    "y_train = df.iloc[:,-1].map({'LOW': 0, 'HIGH': 1}).values[0:-100]\n",
    "\n",
    "x_test = df.iloc[:,0:-1].values[-100::]\n",
    "y_test = df.iloc[:,-1].map({'LOW': 0, 'HIGH': 1}).values[-100::]\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "step_size = x_train.shape[1]\n",
    "nb_features = x_train.shape[2]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 2, 20)             180       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2, 15)             315       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1, 15)             0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 527\n",
      "Trainable params: 527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 1s 4ms/step - loss: 1.6457 - accuracy: 0.5199 - val_loss: 0.6772 - val_accuracy: 0.6400\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6466 - val_loss: 0.7343 - val_accuracy: 0.6300\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6901 - val_loss: 0.7481 - val_accuracy: 0.6200\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6029 - accuracy: 0.6901 - val_loss: 0.7799 - val_accuracy: 0.5700\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6920 - val_loss: 0.7858 - val_accuracy: 0.5800\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.6957 - val_loss: 0.8074 - val_accuracy: 0.5800\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7077 - val_loss: 0.8565 - val_accuracy: 0.5700\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7031 - val_loss: 0.7542 - val_accuracy: 0.6100\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7058 - val_loss: 0.7947 - val_accuracy: 0.5800\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7142 - val_loss: 0.8792 - val_accuracy: 0.5700\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.7021 - val_loss: 0.7788 - val_accuracy: 0.4500\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7188 - val_loss: 0.8232 - val_accuracy: 0.5800\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7299 - val_loss: 0.8834 - val_accuracy: 0.5700\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7271 - val_loss: 0.7948 - val_accuracy: 0.5600\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7197 - val_loss: 0.8563 - val_accuracy: 0.5800\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7428 - val_loss: 0.8425 - val_accuracy: 0.5700\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7354 - val_loss: 0.8665 - val_accuracy: 0.5800\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7336 - val_loss: 0.7679 - val_accuracy: 0.5600\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7493 - val_loss: 0.8040 - val_accuracy: 0.5500\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7512 - val_loss: 0.8267 - val_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7484 - val_loss: 0.8531 - val_accuracy: 0.5900\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 0.7447 - val_loss: 0.8138 - val_accuracy: 0.5800\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7299 - val_loss: 0.8003 - val_accuracy: 0.5800\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7438 - val_loss: 0.8141 - val_accuracy: 0.5700\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7521 - val_loss: 0.8253 - val_accuracy: 0.5500\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7558 - val_loss: 0.7617 - val_accuracy: 0.5400\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7669 - val_loss: 0.8524 - val_accuracy: 0.5700\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7604 - val_loss: 0.8135 - val_accuracy: 0.5700\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7660 - val_loss: 0.7959 - val_accuracy: 0.5600\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7724 - val_loss: 0.7805 - val_accuracy: 0.5900\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7558 - val_loss: 0.7957 - val_accuracy: 0.5100\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7549 - val_loss: 0.7835 - val_accuracy: 0.4800\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7650 - val_loss: 0.7940 - val_accuracy: 0.6200\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7623 - val_loss: 0.8091 - val_accuracy: 0.5200\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7604 - val_loss: 0.7866 - val_accuracy: 0.5700\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7595 - val_loss: 0.8390 - val_accuracy: 0.5900\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7706 - val_loss: 0.7722 - val_accuracy: 0.5500\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7752 - val_loss: 0.8049 - val_accuracy: 0.5400\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7780 - val_loss: 0.7592 - val_accuracy: 0.5300\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7623 - val_loss: 0.8068 - val_accuracy: 0.6100\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7678 - val_loss: 0.7648 - val_accuracy: 0.5200\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7761 - val_loss: 0.8338 - val_accuracy: 0.5500\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7752 - val_loss: 0.7733 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7669 - val_loss: 0.7861 - val_accuracy: 0.5900\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7734 - val_loss: 0.8177 - val_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7789 - val_loss: 0.7221 - val_accuracy: 0.5300\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7734 - val_loss: 0.8459 - val_accuracy: 0.5700\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7845 - val_loss: 0.7446 - val_accuracy: 0.5500\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7826 - val_loss: 0.7836 - val_accuracy: 0.5900\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7771 - val_loss: 0.7643 - val_accuracy: 0.4700\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7826 - val_loss: 0.8254 - val_accuracy: 0.5700\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7835 - val_loss: 0.7855 - val_accuracy: 0.5300\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.8002 - val_loss: 0.7813 - val_accuracy: 0.5500\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.7767 - val_accuracy: 0.5600\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7937 - val_loss: 0.8319 - val_accuracy: 0.5500\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7993 - val_loss: 0.7787 - val_accuracy: 0.5100\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7909 - val_loss: 0.8358 - val_accuracy: 0.5600\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7956 - val_loss: 0.7406 - val_accuracy: 0.5200\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7965 - val_loss: 0.7939 - val_accuracy: 0.5500\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4207 - accuracy: 0.8039 - val_loss: 0.7653 - val_accuracy: 0.5500\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8030 - val_loss: 0.7544 - val_accuracy: 0.5600\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7826 - val_loss: 0.7794 - val_accuracy: 0.5200\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.8113 - val_loss: 0.7889 - val_accuracy: 0.5600\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8067 - val_loss: 0.7945 - val_accuracy: 0.5100\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7900 - val_loss: 0.7754 - val_accuracy: 0.5300\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.7993 - val_loss: 0.8273 - val_accuracy: 0.5300\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8002 - val_loss: 0.7367 - val_accuracy: 0.4900\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8122 - val_loss: 0.7306 - val_accuracy: 0.5700\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8030 - val_loss: 0.7621 - val_accuracy: 0.5200\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8094 - val_loss: 0.8287 - val_accuracy: 0.5400\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.7993 - val_loss: 0.8445 - val_accuracy: 0.5500\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.8030 - val_loss: 0.7777 - val_accuracy: 0.5200\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8187 - val_loss: 0.7526 - val_accuracy: 0.5300\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.8113 - val_loss: 0.7487 - val_accuracy: 0.5500\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.7900 - val_loss: 0.8788 - val_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8039 - val_loss: 0.8061 - val_accuracy: 0.5200\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8104 - val_loss: 0.7734 - val_accuracy: 0.5500\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8178 - val_loss: 0.7807 - val_accuracy: 0.5600\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8252 - val_loss: 0.7582 - val_accuracy: 0.5700\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8104 - val_loss: 0.8101 - val_accuracy: 0.5400\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.8113 - val_loss: 0.7768 - val_accuracy: 0.5500\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8215 - val_loss: 0.8055 - val_accuracy: 0.5400\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8094 - val_loss: 0.7863 - val_accuracy: 0.5900\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.8224 - val_loss: 0.8025 - val_accuracy: 0.6200\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8178 - val_loss: 0.8692 - val_accuracy: 0.5500\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8187 - val_loss: 0.8043 - val_accuracy: 0.5700\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8131 - val_loss: 0.8265 - val_accuracy: 0.5700\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8279 - val_loss: 0.7915 - val_accuracy: 0.6100\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8159 - val_loss: 0.8579 - val_accuracy: 0.5600\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8122 - val_loss: 0.8567 - val_accuracy: 0.5900\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8205 - val_loss: 0.9518 - val_accuracy: 0.5800\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8067 - val_loss: 0.8565 - val_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8141 - val_loss: 0.8243 - val_accuracy: 0.5900\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8131 - val_loss: 0.8750 - val_accuracy: 0.5600\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8159 - val_loss: 0.9720 - val_accuracy: 0.5100\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8168 - val_loss: 0.9878 - val_accuracy: 0.5800\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8205 - val_loss: 0.8877 - val_accuracy: 0.5800\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8224 - val_loss: 0.8729 - val_accuracy: 0.6600\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8242 - val_loss: 0.9661 - val_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8252 - val_loss: 0.9981 - val_accuracy: 0.5700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2676e3257c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(20, 8, activation=\"relu\", input_shape=(9,1)))\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=100, validation_data=(x_test,y_test))\n",
    "\n",
    "\n",
    "# CNN\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(activation='relu', input_shape=(step_size, nb_features), strides=3, filters=20, kernel_size=4))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(strides=4, filters=nb_features, kernel_size=2))\n",
    "\n",
    "# model.compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "# model.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=8, epochs=100)\n",
    "\n",
    "# LSTM\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(units=100,activation='relu', input_shape=(step_size,nb_features),return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(2))\n",
    "# model.add(LeakyReLU())\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit(x_train, y_train, batch_size=2,validation_data=(x_test,y_test), epochs = 100)\n",
    "\n",
    "# GRU\n",
    "# model = Sequential()\n",
    "# model.add(GRU(units=50, input_shape=(step_size,nb_features),return_sequences=False))\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(2))\n",
    "# model.add(Activation('relu'))\n",
    "# model.compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "# model.fit(x_train, y_train, batch_size=8,validation_data=(x_test,y_test), epochs = 100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f987080815062b92e0d4194d9c61d2986c059e9c500745da0633f9971a73526"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('lab': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
