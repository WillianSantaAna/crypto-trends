{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9bd817-e8ed-43e7-8398-9e8a4b08d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a91643-49c2-437a-8887-2d14bede0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição da seed do python\n",
    "seed(1)\n",
    "# e seed do tensorflow\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f101b42a-2767-4501-a9c5-bc77b1a4e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição do ficheiro de dados (treino/validação)\n",
    "symbol = 'btc'\n",
    "crypto_ta_dataset_fp = \"dataset3/crypto_ta_\" + symbol + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0f0508-67cf-4501-bb3a-bca61e3e2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das classses\n",
    "class_names = ['Very Low', 'Low', 'High', 'Very High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721b9bc1-dcb8-4e66-831c-4d970bf21a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sma_7    sma_25    sma_99   sma_200     ema_8    ema_20    sma_vol  \\\n",
      "0  0.389069  0.180146 -0.065214  0.251872  0.382682  0.219033  -3.532641   \n",
      "1  0.498987  0.138913 -0.058568  0.255225  0.347571  0.219784  -7.599545   \n",
      "2  0.231342  0.094671 -0.051021  0.252297  0.117309  0.132675  -8.452679   \n",
      "3  0.198266  0.129483 -0.046158  0.250075  0.116104  0.130672 -12.107501   \n",
      "4  0.340448  0.195801 -0.029580  0.260357  0.499679  0.295022 -11.063468   \n",
      "\n",
      "   bbands_up  bbands_mid  bbands_low  ...        cmo      macd  macdsignal  \\\n",
      "0   0.385451    0.157722   -0.078178  ...  25.485288  2.719071    1.913054   \n",
      "1   0.279253    0.066455   -0.155002  ...  27.317637  3.153088    2.161061   \n",
      "2   0.170194    0.062599   -0.049862  ...  17.979856  3.224742    2.373797   \n",
      "3   0.176183    0.153805    0.130365  ...  19.031101  3.282343    2.555506   \n",
      "4   0.484177    0.281719    0.069544  ...  33.989614  3.917394    2.827884   \n",
      "\n",
      "   macdhist       ppo       roc      rocr  linearreg       tsf  trend  \n",
      "0  0.806017  0.679918  1.184660  1.011847   0.406313  0.434088   HIGH  \n",
      "1  0.992028  0.725128  0.226762  1.002268   0.472719  0.515619    LOW  \n",
      "2  0.850945  0.724181 -0.676195  0.993238   0.170529  0.171168   HIGH  \n",
      "3  0.726837  0.763782  0.111909  1.001119   0.175099  0.178451   HIGH  \n",
      "4  1.089510  0.868475  1.835214  1.018352   0.692356  0.762307   HIGH  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Features: Index(['sma_7', 'sma_25', 'sma_99', 'sma_200', 'ema_8', 'ema_20', 'sma_vol',\n",
      "       'bbands_up', 'bbands_mid', 'bbands_low', 'rsi', 'cmo', 'macd',\n",
      "       'macdsignal', 'macdhist', 'ppo', 'roc', 'rocr', 'linearreg', 'tsf'],\n",
      "      dtype='object')\n",
      "Label: trend\n"
     ]
    }
   ],
   "source": [
    "# ler o ficheiro de dados, indicando o ficheiro e indicamos os nomes das colunas (que não estão no ficheiro)\n",
    "crypto_ta_dataset = pd.read_csv(crypto_ta_dataset_fp)\n",
    "# remover as colunas que nao interessam\n",
    "# crypto_ta_dataset.drop('bbands_up', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('bbands_mid', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('bbands_low', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('macd', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('macdsignal', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('macdhist', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('roc', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('rocr', axis=1, inplace=True)\n",
    "# imprime um as primeiras linhas dos dados\n",
    "print(crypto_ta_dataset.head())\n",
    "\n",
    "# crypto_ta_dataset['sma_7'] = [x * 100 for x in crypto_ta_dataset['sma_7']]\n",
    "# crypto_ta_dataset['sma_25'] = [x * 100 for x in crypto_ta_dataset['sma_25']]\n",
    "# crypto_ta_dataset['sma_99'] = [x * 100 for x in crypto_ta_dataset['sma_99']]\n",
    "# crypto_ta_dataset['ema_8'] = [x * 100 for x in crypto_ta_dataset['ema_8']]\n",
    "# crypto_ta_dataset['ema_20'] = [x * 100 for x in crypto_ta_dataset['ema_20']]\n",
    "# crypto_ta_dataset['bbands_up'] = [x * 100 for x in crypto_ta_dataset['bbands_up']]\n",
    "# crypto_ta_dataset['bbands_mid'] = [x * 100 for x in crypto_ta_dataset['bbands_mid']]\n",
    "# crypto_ta_dataset['bbands_low'] = [x * 100 for x in crypto_ta_dataset['bbands_low']]\n",
    "\n",
    "# colunas que são features e coluna que é a label (a ultima neste caso)\n",
    "feature_names = crypto_ta_dataset.columns[:-1]\n",
    "label_name = crypto_ta_dataset.columns[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6f7ad5-57df-4355-a950-5933cbe63e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sma_7    sma_25    sma_99   sma_200     ema_8    ema_20    sma_vol  \\\n",
      "0      0.389069  0.180146 -0.065214  0.251872  0.382682  0.219033  -3.532641   \n",
      "1      0.498987  0.138913 -0.058568  0.255225  0.347571  0.219784  -7.599545   \n",
      "2      0.231342  0.094671 -0.051021  0.252297  0.117309  0.132675  -8.452679   \n",
      "3      0.198266  0.129483 -0.046158  0.250075  0.116104  0.130672 -12.107501   \n",
      "4      0.340448  0.195801 -0.029580  0.260357  0.499679  0.295022 -11.063468   \n",
      "...         ...       ...       ...       ...       ...       ...        ...   \n",
      "22700 -0.155741 -0.137875 -0.024924  0.012674 -0.104886 -0.113915  -0.394903   \n",
      "22701 -0.205752 -0.125204 -0.019734  0.015449  0.050839 -0.046804  -0.509280   \n",
      "22702 -0.174705 -0.112871 -0.025720  0.016703  0.013208 -0.053574  -0.610728   \n",
      "22703  0.082261 -0.004702 -0.001615  0.027847  0.322070  0.084389  -0.567466   \n",
      "22704  0.415341  0.002867 -0.009235  0.029517  0.364738  0.125434  -0.689503   \n",
      "\n",
      "       bbands_up  bbands_mid  bbands_low  ...        cmo        macd  \\\n",
      "0       0.385451    0.157722   -0.078178  ...  25.485288    2.719071   \n",
      "1       0.279253    0.066455   -0.155002  ...  27.317637    3.153088   \n",
      "2       0.170194    0.062599   -0.049862  ...  17.979856    3.224742   \n",
      "3       0.176183    0.153805    0.130365  ...  19.031101    3.282343   \n",
      "4       0.484177    0.281719    0.069544  ...  33.989614    3.917394   \n",
      "...          ...         ...         ...  ...        ...         ...   \n",
      "22700  -0.029994   -0.079992   -0.131461  ... -22.501102 -355.106432   \n",
      "22701  -0.013500   -0.023148   -0.033089  ... -11.950407 -330.345901   \n",
      "22702  -0.022499   -0.034553   -0.046976  ... -13.543708 -311.696727   \n",
      "22703   0.090264    0.038486   -0.014893  ...   7.758766 -240.030070   \n",
      "22704   0.087666    0.022649   -0.044449  ...  14.177349 -161.340963   \n",
      "\n",
      "       macdsignal    macdhist       ppo       roc      rocr  linearreg  \\\n",
      "0        1.913054    0.806017  0.679918  1.184660  1.011847   0.406313   \n",
      "1        2.161061    0.992028  0.725128  0.226762  1.002268   0.472719   \n",
      "2        2.373797    0.850945  0.724181 -0.676195  0.993238   0.170529   \n",
      "3        2.555506    0.726837  0.763782  0.111909  1.001119   0.175099   \n",
      "4        2.827884    1.089510  0.868475  1.835214  1.018352   0.692356   \n",
      "...           ...         ...       ...       ...       ...        ...   \n",
      "22700 -315.619217  -39.487215 -0.584699  0.064799  1.000648  -0.189595   \n",
      "22701 -318.564554  -11.781347 -0.530143  0.598464  1.005985   0.033310   \n",
      "22702 -317.190988    5.494262 -0.450203 -0.118201  0.998818  -0.122086   \n",
      "22703 -301.758805   61.728734 -0.359674  1.402444  1.014024   0.356974   \n",
      "22704 -273.675236  112.334273 -0.270620  0.511944  1.005119   0.436623   \n",
      "\n",
      "            tsf  trend  \n",
      "0      0.434088      2  \n",
      "1      0.515619      1  \n",
      "2      0.171168      2  \n",
      "3      0.178451      2  \n",
      "4      0.762307      2  \n",
      "...         ...    ...  \n",
      "22700 -0.205185      2  \n",
      "22701  0.048311      1  \n",
      "22702 -0.141452      2  \n",
      "22703  0.405522      2  \n",
      "22704  0.488908      1  \n",
      "\n",
      "[22705 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "crypto_ta_dataset[label_name] = crypto_ta_dataset[label_name].map(\n",
    "    {\"V_LOW\":0,\"LOW\":1,\"HIGH\":2,\"V_HIGH\":3})\n",
    "\n",
    "print(crypto_ta_dataset)\n",
    "# criamos duas variáveis, uma para os dados e outra para as labels (vamos precisar depois)\n",
    "features = crypto_ta_dataset.copy()\n",
    "labels = features.pop(label_name)\n",
    "# normalization dataset\n",
    "# features = tf.keras.utils.normalize(features, axis=-1, order=2)\n",
    "\n",
    "# imprime um resumo dos valores\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e4e1ad-dd5a-4572-854f-b72704d563ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns_plot = sns.pairplot(crypto_ta_dataset,hue=label_name,palette='Set2')\n",
    "# sns_plot.savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5625609a-955f-4702-bb22-03847c4796c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir a estrutra a rede neuronal a utilizar\n",
    "# Neste caso temos duas camadas escondidas com 10 nós\n",
    "#     - Ativação do tipo relu (podem usar outras mas podem também escolher manter)\n",
    "#     - Dense significa que cada camada liga a todas as outras (recomendado)\n",
    "#     - Na primeira camada escondida indica-se, no parametro input_shape, que temos  entradas\n",
    "# A camada de saída deve ter o mesmo número de saídas que o número de classes\n",
    "#     - Por default a camada de saída devolve um logit para cada classe.\n",
    "#     - Um logit é um numero entre -Inf e +Inf que representa a classificação antes de ser normalizada\n",
    "#     - Podemos normalizar o resultado depois  para probalidades (usando a função softmax)\n",
    "#     - Podemos também indicar que esta camada usa logo a softmax mas não é recomendado\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu, input_shape=(20,)),  # input shape required\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec1e380-0d8f-415a-a760-5d3f9af6126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir as configurações do algoritmo\n",
    "# - Algoritmo usado para optimização (neste caso o SGD) com a learning rate \n",
    "#    - Podem decidir ajustar este parametro mas não é obrigatório\n",
    "# - Função que será usada para a minimização na procura\n",
    "#    - Neste caso usamos a SparseCategoricalCrossentropy\n",
    "#    - SparseCategorical é usada quanda trabalhamos com inteiros como target\n",
    "#    - from_logits=True indica que a saída da rede são logits\n",
    "#        - Se não usarmos este parametro temos de usar a softmax na saída da rede\n",
    "# - As metricas não são usadas para optimização, são usadas para dar output de resultados\n",
    "#    - Podem-se usar várias métricas ao mesmo tempo, dará vários valores de output\n",
    "#    - Neste caso estamos a usar a Accuracy (número )\n",
    "\n",
    "# definir as configurações do algoritmo\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721fbfe0-9a01-4086-bd70-ad00a517de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Criar o Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Percentages de teste e validação\n",
    "TEST_PERC = 0.1\n",
    "VALID_PERC = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4b64f9-686a-4016-90e7-665bc99e073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf.Tensor(-2, shape=(), dtype=int64)\n",
      "22705 263 10844 11283 315\n"
     ]
    }
   ],
   "source": [
    "# 2- Separar por classe (vai permitir garantir que cada conjunto tem X de cada classe)\n",
    "class0_dataset = dataset.filter(lambda x, y: y == 0)\n",
    "class1_dataset = dataset.filter(lambda x, y: y == 1)\n",
    "class2_dataset = dataset.filter(lambda x, y: y == 2)\n",
    "class3_dataset = dataset.filter(lambda x, y: y == 3)\n",
    "print()\n",
    "print(class0_dataset.cardinality())\n",
    "# quantidade de cada classe e total\n",
    "DATASIZE = dataset.cardinality().numpy()\n",
    "c0_size = len(list(class0_dataset))\n",
    "c1_size = len(list(class1_dataset))\n",
    "c2_size = len(list(class2_dataset))\n",
    "c3_size = len(list(class3_dataset))\n",
    "print(DATASIZE,c0_size,c1_size,c2_size,c3_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38de53ad-9115-47ac-bb57-a4fe6311ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- Baralhar\n",
    "class0_dataset = class0_dataset.shuffle(DATASIZE)\n",
    "class1_dataset = class1_dataset.shuffle(DATASIZE)\n",
    "class2_dataset = class2_dataset.shuffle(DATASIZE)\n",
    "class3_dataset = class3_dataset.shuffle(DATASIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c93619e-26ff-4d07-ba2a-c7ea548b5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- Partir cada um\n",
    "# Primeiro retiramos o teste\n",
    "class0_test = class0_dataset.take(int(c0_size*TEST_PERC))\n",
    "# variável temporária para separar entre treino e validação\n",
    "# skip significa que vai ficar com o resto dos dados\n",
    "rest = class0_dataset.skip(int(c0_size*TEST_PERC))\n",
    "class0_validation = rest.take(int(c0_size*VALID_PERC))\n",
    "class0_train = rest.skip(int(c0_size*VALID_PERC))\n",
    "\n",
    "class1_test = class1_dataset.take(int(c1_size*TEST_PERC))\n",
    "rest = class1_dataset.skip(int(c1_size*TEST_PERC))\n",
    "class1_validation = rest.take(int(c1_size*VALID_PERC))\n",
    "class1_train = rest.skip(int(c1_size*VALID_PERC))\n",
    "\n",
    "class2_test = class2_dataset.take(int(c2_size*TEST_PERC))\n",
    "rest = class2_dataset.skip(int(c2_size*TEST_PERC))\n",
    "class2_validation = rest.take(int(c2_size*VALID_PERC))\n",
    "class2_train = rest.skip(int(c2_size*VALID_PERC))\n",
    "\n",
    "class3_test = class3_dataset.take(int(c3_size*TEST_PERC))\n",
    "rest = class3_dataset.skip(int(c3_size*TEST_PERC))\n",
    "class3_validation = rest.take(int(c3_size*VALID_PERC))\n",
    "class3_train = rest.skip(int(c3_size*VALID_PERC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a303faf3-5b07-4fb1-9a13-bd289aacf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size =  18167\n",
      "Validation dataset size =  2269\n",
      "Test dataset size =  2269\n"
     ]
    }
   ],
   "source": [
    "#5- Juntar tudo novamente\n",
    "train_dataset = class0_train.concatenate(class1_train).concatenate(class2_train).concatenate(class3_train).shuffle(DATASIZE)\n",
    "test_dataset = class0_test.concatenate(class1_test).concatenate(class2_test).concatenate(class3_test).shuffle(DATASIZE)\n",
    "validation_dataset = class0_validation.concatenate(class1_validation).concatenate(class2_validation).concatenate(class3_validation).shuffle(DATASIZE)\n",
    "\n",
    "#confirmar tamanhos\n",
    "print('Train dataset size = ', len(list(train_dataset)))\n",
    "print('Validation dataset size = ', len(list(validation_dataset)))\n",
    "print('Test dataset size = ', len(list(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999bb8c6-0113-4572-83d0-7a33aa9e4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6- Usar o dataset diretamente para treinar, validar e testar\n",
    "\n",
    "# Converter o conjunto de treino de novo para o formato inicial (DataFrame)\n",
    "feat,lab = map(list,zip(*list(train_dataset.as_numpy_iterator())))\n",
    "train_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "train_labels = pd.DataFrame(data=lab,columns=[label_name])\n",
    "\n",
    "feat,lab = map(list,zip(*list(validation_dataset.as_numpy_iterator())))\n",
    "valid_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "valid_labels = pd.DataFrame(data=lab,columns=[label_name])\n",
    "\n",
    "feat,lab = map(list,zip(*list(test_dataset.as_numpy_iterator())))\n",
    "test_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "test_labels = pd.DataFrame(data=lab,columns=[label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6d7b5c-9ad6-49cb-8a4f-54d640b7b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.9763 - sparse_categorical_accuracy: 0.4976 - val_loss: 0.8792 - val_sparse_categorical_accuracy: 0.5134\n",
      "Epoch 2/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8617 - sparse_categorical_accuracy: 0.5135 - val_loss: 0.8291 - val_sparse_categorical_accuracy: 0.5108\n",
      "Epoch 3/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8371 - sparse_categorical_accuracy: 0.5110 - val_loss: 0.8257 - val_sparse_categorical_accuracy: 0.5209\n",
      "Epoch 4/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8231 - sparse_categorical_accuracy: 0.5128 - val_loss: 0.8525 - val_sparse_categorical_accuracy: 0.4971\n",
      "Epoch 5/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8255 - sparse_categorical_accuracy: 0.5140 - val_loss: 0.8302 - val_sparse_categorical_accuracy: 0.5126\n",
      "Epoch 6/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8148 - sparse_categorical_accuracy: 0.5153 - val_loss: 0.8062 - val_sparse_categorical_accuracy: 0.5104\n",
      "Epoch 7/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8134 - sparse_categorical_accuracy: 0.5143 - val_loss: 0.8020 - val_sparse_categorical_accuracy: 0.5143\n",
      "Epoch 8/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8087 - sparse_categorical_accuracy: 0.5167 - val_loss: 0.7896 - val_sparse_categorical_accuracy: 0.5201\n",
      "Epoch 9/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8050 - sparse_categorical_accuracy: 0.5200 - val_loss: 0.8212 - val_sparse_categorical_accuracy: 0.5187\n",
      "Epoch 10/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8037 - sparse_categorical_accuracy: 0.5193 - val_loss: 0.7993 - val_sparse_categorical_accuracy: 0.5161\n",
      "Epoch 11/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8000 - sparse_categorical_accuracy: 0.5191 - val_loss: 0.7908 - val_sparse_categorical_accuracy: 0.5223\n",
      "Epoch 12/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7965 - sparse_categorical_accuracy: 0.5220 - val_loss: 0.7830 - val_sparse_categorical_accuracy: 0.5245\n",
      "Epoch 13/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7937 - sparse_categorical_accuracy: 0.5164 - val_loss: 0.7834 - val_sparse_categorical_accuracy: 0.5192\n",
      "Epoch 14/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7925 - sparse_categorical_accuracy: 0.5174 - val_loss: 0.7851 - val_sparse_categorical_accuracy: 0.5205\n",
      "Epoch 15/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7917 - sparse_categorical_accuracy: 0.5230 - val_loss: 0.7912 - val_sparse_categorical_accuracy: 0.5108\n",
      "Epoch 16/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7879 - sparse_categorical_accuracy: 0.5225 - val_loss: 0.7807 - val_sparse_categorical_accuracy: 0.5253\n",
      "Epoch 17/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7882 - sparse_categorical_accuracy: 0.5253 - val_loss: 0.8073 - val_sparse_categorical_accuracy: 0.5236\n",
      "Epoch 18/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7871 - sparse_categorical_accuracy: 0.5243 - val_loss: 0.7802 - val_sparse_categorical_accuracy: 0.5249\n",
      "Epoch 19/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7872 - sparse_categorical_accuracy: 0.5226 - val_loss: 0.7818 - val_sparse_categorical_accuracy: 0.5253\n",
      "Epoch 20/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7842 - sparse_categorical_accuracy: 0.5234 - val_loss: 0.7935 - val_sparse_categorical_accuracy: 0.5046\n",
      "Epoch 21/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7831 - sparse_categorical_accuracy: 0.5249 - val_loss: 0.7748 - val_sparse_categorical_accuracy: 0.5372\n",
      "Epoch 22/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7810 - sparse_categorical_accuracy: 0.5275 - val_loss: 0.7830 - val_sparse_categorical_accuracy: 0.5051\n",
      "Epoch 23/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7810 - sparse_categorical_accuracy: 0.5252 - val_loss: 0.7737 - val_sparse_categorical_accuracy: 0.5205\n",
      "Epoch 24/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7805 - sparse_categorical_accuracy: 0.5251 - val_loss: 0.7759 - val_sparse_categorical_accuracy: 0.5381\n",
      "Epoch 25/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7778 - sparse_categorical_accuracy: 0.5290 - val_loss: 0.7887 - val_sparse_categorical_accuracy: 0.5223\n",
      "Epoch 26/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7791 - sparse_categorical_accuracy: 0.5269 - val_loss: 0.7802 - val_sparse_categorical_accuracy: 0.5156\n",
      "Epoch 27/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7766 - sparse_categorical_accuracy: 0.5274 - val_loss: 0.7689 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 28/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7758 - sparse_categorical_accuracy: 0.5282 - val_loss: 0.7738 - val_sparse_categorical_accuracy: 0.5245\n",
      "Epoch 29/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7752 - sparse_categorical_accuracy: 0.5279 - val_loss: 0.7678 - val_sparse_categorical_accuracy: 0.5240\n",
      "Epoch 30/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7750 - sparse_categorical_accuracy: 0.5308 - val_loss: 0.7783 - val_sparse_categorical_accuracy: 0.5227\n",
      "Epoch 31/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7739 - sparse_categorical_accuracy: 0.5284 - val_loss: 0.7735 - val_sparse_categorical_accuracy: 0.5275\n",
      "Epoch 32/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7737 - sparse_categorical_accuracy: 0.5343 - val_loss: 0.7688 - val_sparse_categorical_accuracy: 0.5324\n",
      "Epoch 33/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7699 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7759 - val_sparse_categorical_accuracy: 0.5161\n",
      "Epoch 34/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7701 - sparse_categorical_accuracy: 0.5332 - val_loss: 0.7836 - val_sparse_categorical_accuracy: 0.5253\n",
      "Epoch 35/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7697 - sparse_categorical_accuracy: 0.5312 - val_loss: 0.7843 - val_sparse_categorical_accuracy: 0.5390\n",
      "Epoch 36/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7696 - sparse_categorical_accuracy: 0.5311 - val_loss: 0.7708 - val_sparse_categorical_accuracy: 0.5359\n",
      "Epoch 37/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7688 - sparse_categorical_accuracy: 0.5357 - val_loss: 0.7649 - val_sparse_categorical_accuracy: 0.5359\n",
      "Epoch 38/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7682 - sparse_categorical_accuracy: 0.5334 - val_loss: 0.7689 - val_sparse_categorical_accuracy: 0.5297\n",
      "Epoch 39/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7671 - sparse_categorical_accuracy: 0.5312 - val_loss: 0.7665 - val_sparse_categorical_accuracy: 0.5346\n",
      "Epoch 40/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7671 - sparse_categorical_accuracy: 0.5371 - val_loss: 0.7653 - val_sparse_categorical_accuracy: 0.5394\n",
      "Epoch 41/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7667 - sparse_categorical_accuracy: 0.5337 - val_loss: 0.7716 - val_sparse_categorical_accuracy: 0.5258\n",
      "Epoch 42/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7664 - sparse_categorical_accuracy: 0.5353 - val_loss: 0.7640 - val_sparse_categorical_accuracy: 0.5346\n",
      "Epoch 43/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7651 - sparse_categorical_accuracy: 0.5409 - val_loss: 0.7615 - val_sparse_categorical_accuracy: 0.5456\n",
      "Epoch 44/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7630 - sparse_categorical_accuracy: 0.5431 - val_loss: 0.7694 - val_sparse_categorical_accuracy: 0.5328\n",
      "Epoch 45/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7622 - sparse_categorical_accuracy: 0.5367 - val_loss: 0.7720 - val_sparse_categorical_accuracy: 0.5306\n",
      "Epoch 46/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7604 - sparse_categorical_accuracy: 0.5405 - val_loss: 0.7642 - val_sparse_categorical_accuracy: 0.5443\n",
      "Epoch 47/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7645 - sparse_categorical_accuracy: 0.5374 - val_loss: 0.7637 - val_sparse_categorical_accuracy: 0.5355\n",
      "Epoch 48/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7592 - sparse_categorical_accuracy: 0.5444 - val_loss: 0.7571 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 49/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7602 - sparse_categorical_accuracy: 0.5442 - val_loss: 0.7635 - val_sparse_categorical_accuracy: 0.5390\n",
      "Epoch 50/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7592 - sparse_categorical_accuracy: 0.5421 - val_loss: 0.7673 - val_sparse_categorical_accuracy: 0.5469\n",
      "Epoch 51/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7582 - sparse_categorical_accuracy: 0.5426 - val_loss: 0.7626 - val_sparse_categorical_accuracy: 0.5430\n",
      "Epoch 52/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7576 - sparse_categorical_accuracy: 0.5448 - val_loss: 0.7588 - val_sparse_categorical_accuracy: 0.5522\n",
      "Epoch 53/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7572 - sparse_categorical_accuracy: 0.5442 - val_loss: 0.7588 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 54/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7559 - sparse_categorical_accuracy: 0.5414 - val_loss: 0.7646 - val_sparse_categorical_accuracy: 0.5478\n",
      "Epoch 55/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7559 - sparse_categorical_accuracy: 0.5481 - val_loss: 0.7651 - val_sparse_categorical_accuracy: 0.5434\n",
      "Epoch 56/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7551 - sparse_categorical_accuracy: 0.5452 - val_loss: 0.7687 - val_sparse_categorical_accuracy: 0.5430\n",
      "Epoch 57/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7546 - sparse_categorical_accuracy: 0.5480 - val_loss: 0.7634 - val_sparse_categorical_accuracy: 0.5364\n",
      "Epoch 58/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7531 - sparse_categorical_accuracy: 0.5459 - val_loss: 0.7701 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 59/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7536 - sparse_categorical_accuracy: 0.5444 - val_loss: 0.7663 - val_sparse_categorical_accuracy: 0.5377\n",
      "Epoch 60/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7516 - sparse_categorical_accuracy: 0.5431 - val_loss: 0.7592 - val_sparse_categorical_accuracy: 0.5487\n",
      "Epoch 61/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7515 - sparse_categorical_accuracy: 0.5519 - val_loss: 0.7552 - val_sparse_categorical_accuracy: 0.5597\n",
      "Epoch 62/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7508 - sparse_categorical_accuracy: 0.5490 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.5425\n",
      "Epoch 63/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7487 - sparse_categorical_accuracy: 0.5514 - val_loss: 0.7580 - val_sparse_categorical_accuracy: 0.5465\n",
      "Epoch 64/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7490 - sparse_categorical_accuracy: 0.5514 - val_loss: 0.7565 - val_sparse_categorical_accuracy: 0.5337\n",
      "Epoch 65/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7482 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7583 - val_sparse_categorical_accuracy: 0.5425\n",
      "Epoch 66/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7478 - sparse_categorical_accuracy: 0.5519 - val_loss: 0.7534 - val_sparse_categorical_accuracy: 0.5580\n",
      "Epoch 67/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7470 - sparse_categorical_accuracy: 0.5555 - val_loss: 0.7603 - val_sparse_categorical_accuracy: 0.5461\n",
      "Epoch 68/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7462 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7605 - val_sparse_categorical_accuracy: 0.5500\n",
      "Epoch 69/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7450 - sparse_categorical_accuracy: 0.5549 - val_loss: 0.7519 - val_sparse_categorical_accuracy: 0.5668\n",
      "Epoch 70/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7430 - sparse_categorical_accuracy: 0.5559 - val_loss: 0.7566 - val_sparse_categorical_accuracy: 0.5447\n",
      "Epoch 71/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7434 - sparse_categorical_accuracy: 0.5562 - val_loss: 0.7496 - val_sparse_categorical_accuracy: 0.5491\n",
      "Epoch 72/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7435 - sparse_categorical_accuracy: 0.5598 - val_loss: 0.7550 - val_sparse_categorical_accuracy: 0.5491\n",
      "Epoch 73/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7440 - sparse_categorical_accuracy: 0.5557 - val_loss: 0.7552 - val_sparse_categorical_accuracy: 0.5513\n",
      "Epoch 74/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7419 - sparse_categorical_accuracy: 0.5581 - val_loss: 0.7552 - val_sparse_categorical_accuracy: 0.5531\n",
      "Epoch 75/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7425 - sparse_categorical_accuracy: 0.5568 - val_loss: 0.7617 - val_sparse_categorical_accuracy: 0.5500\n",
      "Epoch 76/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7402 - sparse_categorical_accuracy: 0.5585 - val_loss: 0.7517 - val_sparse_categorical_accuracy: 0.5531\n",
      "Epoch 77/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7392 - sparse_categorical_accuracy: 0.5627 - val_loss: 0.7651 - val_sparse_categorical_accuracy: 0.5447\n",
      "Epoch 78/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7401 - sparse_categorical_accuracy: 0.5583 - val_loss: 0.7534 - val_sparse_categorical_accuracy: 0.5465\n",
      "Epoch 79/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7386 - sparse_categorical_accuracy: 0.5635 - val_loss: 0.7597 - val_sparse_categorical_accuracy: 0.5399\n",
      "Epoch 80/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7368 - sparse_categorical_accuracy: 0.5679 - val_loss: 0.7585 - val_sparse_categorical_accuracy: 0.5461\n",
      "Epoch 81/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7356 - sparse_categorical_accuracy: 0.5681 - val_loss: 0.7629 - val_sparse_categorical_accuracy: 0.5491\n",
      "Epoch 82/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7351 - sparse_categorical_accuracy: 0.5617 - val_loss: 0.7474 - val_sparse_categorical_accuracy: 0.5703\n",
      "Epoch 83/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7355 - sparse_categorical_accuracy: 0.5632 - val_loss: 0.7505 - val_sparse_categorical_accuracy: 0.5628\n",
      "Epoch 84/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7332 - sparse_categorical_accuracy: 0.5686 - val_loss: 0.7487 - val_sparse_categorical_accuracy: 0.5549\n",
      "Epoch 85/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7336 - sparse_categorical_accuracy: 0.5664 - val_loss: 0.7486 - val_sparse_categorical_accuracy: 0.5584\n",
      "Epoch 86/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7321 - sparse_categorical_accuracy: 0.5661 - val_loss: 0.7511 - val_sparse_categorical_accuracy: 0.5527\n",
      "Epoch 87/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7312 - sparse_categorical_accuracy: 0.5682 - val_loss: 0.7483 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 88/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7312 - sparse_categorical_accuracy: 0.5683 - val_loss: 0.7496 - val_sparse_categorical_accuracy: 0.5778\n",
      "Epoch 89/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7317 - sparse_categorical_accuracy: 0.5626 - val_loss: 0.7503 - val_sparse_categorical_accuracy: 0.5544\n",
      "Epoch 90/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7306 - sparse_categorical_accuracy: 0.5672 - val_loss: 0.7453 - val_sparse_categorical_accuracy: 0.5760\n",
      "Epoch 91/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7299 - sparse_categorical_accuracy: 0.5689 - val_loss: 0.7463 - val_sparse_categorical_accuracy: 0.5663\n",
      "Epoch 92/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7302 - sparse_categorical_accuracy: 0.5738 - val_loss: 0.7452 - val_sparse_categorical_accuracy: 0.5712\n",
      "Epoch 93/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7285 - sparse_categorical_accuracy: 0.5686 - val_loss: 0.7404 - val_sparse_categorical_accuracy: 0.5743\n",
      "Epoch 94/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7269 - sparse_categorical_accuracy: 0.5733 - val_loss: 0.7427 - val_sparse_categorical_accuracy: 0.5756\n",
      "Epoch 95/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7262 - sparse_categorical_accuracy: 0.5683 - val_loss: 0.7496 - val_sparse_categorical_accuracy: 0.5602\n",
      "Epoch 96/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7260 - sparse_categorical_accuracy: 0.5701 - val_loss: 0.7455 - val_sparse_categorical_accuracy: 0.5721\n",
      "Epoch 97/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7248 - sparse_categorical_accuracy: 0.5733 - val_loss: 0.7460 - val_sparse_categorical_accuracy: 0.5580\n",
      "Epoch 98/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7244 - sparse_categorical_accuracy: 0.5732 - val_loss: 0.7460 - val_sparse_categorical_accuracy: 0.5641\n",
      "Epoch 99/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7250 - sparse_categorical_accuracy: 0.5749 - val_loss: 0.7438 - val_sparse_categorical_accuracy: 0.5818\n",
      "Epoch 100/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7223 - sparse_categorical_accuracy: 0.5768 - val_loss: 0.7438 - val_sparse_categorical_accuracy: 0.5641\n",
      "Epoch 101/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7223 - sparse_categorical_accuracy: 0.5776 - val_loss: 0.7458 - val_sparse_categorical_accuracy: 0.5624\n",
      "Epoch 102/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7219 - sparse_categorical_accuracy: 0.5770 - val_loss: 0.7409 - val_sparse_categorical_accuracy: 0.5628\n",
      "Epoch 103/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7205 - sparse_categorical_accuracy: 0.5790 - val_loss: 0.7429 - val_sparse_categorical_accuracy: 0.5857\n",
      "Epoch 104/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7189 - sparse_categorical_accuracy: 0.5768 - val_loss: 0.7465 - val_sparse_categorical_accuracy: 0.5580\n",
      "Epoch 105/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7183 - sparse_categorical_accuracy: 0.5785 - val_loss: 0.7409 - val_sparse_categorical_accuracy: 0.5712\n",
      "Epoch 106/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7185 - sparse_categorical_accuracy: 0.5746 - val_loss: 0.7377 - val_sparse_categorical_accuracy: 0.5637\n",
      "Epoch 107/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7152 - sparse_categorical_accuracy: 0.5808 - val_loss: 0.7463 - val_sparse_categorical_accuracy: 0.5725\n",
      "Epoch 108/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7174 - sparse_categorical_accuracy: 0.5767 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.5694\n",
      "Epoch 109/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7164 - sparse_categorical_accuracy: 0.5798 - val_loss: 0.7361 - val_sparse_categorical_accuracy: 0.5853\n",
      "Epoch 110/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7169 - sparse_categorical_accuracy: 0.5786 - val_loss: 0.7532 - val_sparse_categorical_accuracy: 0.5769\n",
      "Epoch 111/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7136 - sparse_categorical_accuracy: 0.5824 - val_loss: 0.7751 - val_sparse_categorical_accuracy: 0.5430\n",
      "Epoch 112/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7139 - sparse_categorical_accuracy: 0.5818 - val_loss: 0.7481 - val_sparse_categorical_accuracy: 0.5747\n",
      "Epoch 113/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7124 - sparse_categorical_accuracy: 0.5853 - val_loss: 0.7405 - val_sparse_categorical_accuracy: 0.5668\n",
      "Epoch 114/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7123 - sparse_categorical_accuracy: 0.5843 - val_loss: 0.7389 - val_sparse_categorical_accuracy: 0.5685\n",
      "Epoch 115/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7126 - sparse_categorical_accuracy: 0.5845 - val_loss: 0.7376 - val_sparse_categorical_accuracy: 0.5725\n",
      "Epoch 116/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7113 - sparse_categorical_accuracy: 0.5871 - val_loss: 0.7293 - val_sparse_categorical_accuracy: 0.5809\n",
      "Epoch 117/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7090 - sparse_categorical_accuracy: 0.5843 - val_loss: 0.7391 - val_sparse_categorical_accuracy: 0.5637\n",
      "Epoch 118/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7098 - sparse_categorical_accuracy: 0.5874 - val_loss: 0.7353 - val_sparse_categorical_accuracy: 0.5769\n",
      "Epoch 119/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7079 - sparse_categorical_accuracy: 0.5856 - val_loss: 0.7316 - val_sparse_categorical_accuracy: 0.5835\n",
      "Epoch 120/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7057 - sparse_categorical_accuracy: 0.5861 - val_loss: 0.7389 - val_sparse_categorical_accuracy: 0.5747\n",
      "Epoch 121/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7078 - sparse_categorical_accuracy: 0.5855 - val_loss: 0.7295 - val_sparse_categorical_accuracy: 0.5853\n",
      "Epoch 122/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7064 - sparse_categorical_accuracy: 0.5919 - val_loss: 0.7425 - val_sparse_categorical_accuracy: 0.5760\n",
      "Epoch 123/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7052 - sparse_categorical_accuracy: 0.5902 - val_loss: 0.7336 - val_sparse_categorical_accuracy: 0.5831\n",
      "Epoch 124/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7030 - sparse_categorical_accuracy: 0.5904 - val_loss: 0.7310 - val_sparse_categorical_accuracy: 0.5879\n",
      "Epoch 125/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7049 - sparse_categorical_accuracy: 0.5906 - val_loss: 0.7276 - val_sparse_categorical_accuracy: 0.5862\n",
      "Epoch 126/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7024 - sparse_categorical_accuracy: 0.5893 - val_loss: 0.7364 - val_sparse_categorical_accuracy: 0.5888\n",
      "Epoch 127/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7001 - sparse_categorical_accuracy: 0.5920 - val_loss: 0.7379 - val_sparse_categorical_accuracy: 0.5760\n",
      "Epoch 128/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6998 - sparse_categorical_accuracy: 0.5918 - val_loss: 0.7362 - val_sparse_categorical_accuracy: 0.5831\n",
      "Epoch 129/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6993 - sparse_categorical_accuracy: 0.5930 - val_loss: 0.7336 - val_sparse_categorical_accuracy: 0.5760\n",
      "Epoch 130/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7000 - sparse_categorical_accuracy: 0.5948 - val_loss: 0.7291 - val_sparse_categorical_accuracy: 0.5796\n",
      "Epoch 131/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6995 - sparse_categorical_accuracy: 0.5956 - val_loss: 0.7359 - val_sparse_categorical_accuracy: 0.5826\n",
      "Epoch 132/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.5943 - val_loss: 0.7318 - val_sparse_categorical_accuracy: 0.5681\n",
      "Epoch 133/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6985 - sparse_categorical_accuracy: 0.5931 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.5892\n",
      "Epoch 134/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6970 - sparse_categorical_accuracy: 0.5958 - val_loss: 0.7221 - val_sparse_categorical_accuracy: 0.6003\n",
      "Epoch 135/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6955 - sparse_categorical_accuracy: 0.5974 - val_loss: 0.7212 - val_sparse_categorical_accuracy: 0.5950\n",
      "Epoch 136/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.5969 - val_loss: 0.7223 - val_sparse_categorical_accuracy: 0.5981\n",
      "Epoch 137/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6942 - sparse_categorical_accuracy: 0.5972 - val_loss: 0.7242 - val_sparse_categorical_accuracy: 0.5910\n",
      "Epoch 138/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.5991 - val_loss: 0.7199 - val_sparse_categorical_accuracy: 0.5862\n",
      "Epoch 139/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6910 - sparse_categorical_accuracy: 0.6036 - val_loss: 0.7255 - val_sparse_categorical_accuracy: 0.5897\n",
      "Epoch 140/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.6020 - val_loss: 0.7282 - val_sparse_categorical_accuracy: 0.5906\n",
      "Epoch 141/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6019 - val_loss: 0.7294 - val_sparse_categorical_accuracy: 0.5932\n",
      "Epoch 142/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6886 - sparse_categorical_accuracy: 0.6040 - val_loss: 0.7324 - val_sparse_categorical_accuracy: 0.5826\n",
      "Epoch 143/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5970 - val_loss: 0.7351 - val_sparse_categorical_accuracy: 0.5769\n",
      "Epoch 144/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6908 - sparse_categorical_accuracy: 0.6031 - val_loss: 0.7199 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 145/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.6047 - val_loss: 0.7298 - val_sparse_categorical_accuracy: 0.5914\n",
      "Epoch 146/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.6022 - val_loss: 0.7204 - val_sparse_categorical_accuracy: 0.5937\n",
      "Epoch 147/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.6062 - val_loss: 0.7189 - val_sparse_categorical_accuracy: 0.5857\n",
      "Epoch 148/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.6098 - val_loss: 0.7251 - val_sparse_categorical_accuracy: 0.5804\n",
      "Epoch 149/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6856 - sparse_categorical_accuracy: 0.6069 - val_loss: 0.7168 - val_sparse_categorical_accuracy: 0.6033\n",
      "Epoch 150/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6835 - sparse_categorical_accuracy: 0.6057 - val_loss: 0.7229 - val_sparse_categorical_accuracy: 0.6095\n",
      "Epoch 151/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6825 - sparse_categorical_accuracy: 0.6034 - val_loss: 0.7278 - val_sparse_categorical_accuracy: 0.5888\n",
      "Epoch 152/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6824 - sparse_categorical_accuracy: 0.6087 - val_loss: 0.7252 - val_sparse_categorical_accuracy: 0.5989\n",
      "Epoch 153/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6812 - sparse_categorical_accuracy: 0.6080 - val_loss: 0.7251 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 154/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6823 - sparse_categorical_accuracy: 0.6079 - val_loss: 0.7215 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 155/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6806 - sparse_categorical_accuracy: 0.6117 - val_loss: 0.7204 - val_sparse_categorical_accuracy: 0.5840\n",
      "Epoch 156/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6802 - sparse_categorical_accuracy: 0.6104 - val_loss: 0.7191 - val_sparse_categorical_accuracy: 0.5963\n",
      "Epoch 157/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.6139 - val_loss: 0.7259 - val_sparse_categorical_accuracy: 0.6011\n",
      "Epoch 158/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6776 - sparse_categorical_accuracy: 0.6117 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.5994\n",
      "Epoch 159/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6774 - sparse_categorical_accuracy: 0.6145 - val_loss: 0.7194 - val_sparse_categorical_accuracy: 0.5906\n",
      "Epoch 160/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6764 - sparse_categorical_accuracy: 0.6113 - val_loss: 0.7175 - val_sparse_categorical_accuracy: 0.6060\n",
      "Epoch 161/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6184 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.6086\n",
      "Epoch 162/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6759 - sparse_categorical_accuracy: 0.6171 - val_loss: 0.7243 - val_sparse_categorical_accuracy: 0.5813\n",
      "Epoch 163/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6111 - val_loss: 0.7100 - val_sparse_categorical_accuracy: 0.6179\n",
      "Epoch 164/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6730 - sparse_categorical_accuracy: 0.6188 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.6091\n",
      "Epoch 165/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6126 - val_loss: 0.7254 - val_sparse_categorical_accuracy: 0.6042\n",
      "Epoch 166/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6727 - sparse_categorical_accuracy: 0.6161 - val_loss: 0.7156 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 167/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6194 - val_loss: 0.7161 - val_sparse_categorical_accuracy: 0.6051\n",
      "Epoch 168/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.6187 - val_loss: 0.7236 - val_sparse_categorical_accuracy: 0.5892\n",
      "Epoch 169/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6183 - val_loss: 0.7100 - val_sparse_categorical_accuracy: 0.6011\n",
      "Epoch 170/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6172 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.6152\n",
      "Epoch 171/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6206 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.5910\n",
      "Epoch 172/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6220 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.6157\n",
      "Epoch 173/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6189 - val_loss: 0.7160 - val_sparse_categorical_accuracy: 0.6100\n",
      "Epoch 174/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6222 - val_loss: 0.7200 - val_sparse_categorical_accuracy: 0.5998\n",
      "Epoch 175/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6187 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.6139\n",
      "Epoch 176/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6651 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7204 - val_sparse_categorical_accuracy: 0.6029\n",
      "Epoch 177/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6634 - sparse_categorical_accuracy: 0.6198 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.6078\n",
      "Epoch 178/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6611 - sparse_categorical_accuracy: 0.6247 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.6042\n",
      "Epoch 179/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.7143 - val_sparse_categorical_accuracy: 0.6029\n",
      "Epoch 180/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6611 - sparse_categorical_accuracy: 0.6246 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.5972\n",
      "Epoch 181/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6246 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.6210\n",
      "Epoch 182/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6287 - val_loss: 0.7219 - val_sparse_categorical_accuracy: 0.6161\n",
      "Epoch 183/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6576 - sparse_categorical_accuracy: 0.6266 - val_loss: 0.7241 - val_sparse_categorical_accuracy: 0.5989\n",
      "Epoch 184/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6573 - sparse_categorical_accuracy: 0.6291 - val_loss: 0.7250 - val_sparse_categorical_accuracy: 0.6064\n",
      "Epoch 185/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6296 - val_loss: 0.7136 - val_sparse_categorical_accuracy: 0.6157\n",
      "Epoch 186/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6262 - val_loss: 0.7178 - val_sparse_categorical_accuracy: 0.6016\n",
      "Epoch 187/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6547 - sparse_categorical_accuracy: 0.6306 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.6122\n",
      "Epoch 188/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6535 - sparse_categorical_accuracy: 0.6330 - val_loss: 0.7184 - val_sparse_categorical_accuracy: 0.6148\n",
      "Epoch 189/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6296 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.6205\n",
      "Epoch 190/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6520 - sparse_categorical_accuracy: 0.6365 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.6241\n",
      "Epoch 191/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.6295 - val_loss: 0.7128 - val_sparse_categorical_accuracy: 0.6166\n",
      "Epoch 192/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6339 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.6205\n",
      "Epoch 193/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6499 - sparse_categorical_accuracy: 0.6302 - val_loss: 0.7107 - val_sparse_categorical_accuracy: 0.6139\n",
      "Epoch 194/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6334 - val_loss: 0.7111 - val_sparse_categorical_accuracy: 0.6047\n",
      "Epoch 195/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6335 - val_loss: 0.7056 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 196/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6333 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.6223\n",
      "Epoch 197/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6379 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.6316\n",
      "Epoch 198/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6350 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 199/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6331 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.6399\n",
      "Epoch 200/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6364 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.6214\n",
      "Epoch 201/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6427 - sparse_categorical_accuracy: 0.6403 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.6188\n",
      "Epoch 202/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6438 - sparse_categorical_accuracy: 0.6393 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.6351\n",
      "Epoch 203/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6408 - sparse_categorical_accuracy: 0.6401 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.6267\n",
      "Epoch 204/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6320\n",
      "Epoch 205/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6424 - sparse_categorical_accuracy: 0.6350 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6205\n",
      "Epoch 206/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6386 - sparse_categorical_accuracy: 0.6406 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.6227\n",
      "Epoch 207/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6386 - sparse_categorical_accuracy: 0.6390 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.6214\n",
      "Epoch 208/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6385 - sparse_categorical_accuracy: 0.6403 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.6346\n",
      "Epoch 209/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6357 - sparse_categorical_accuracy: 0.6429 - val_loss: 0.7065 - val_sparse_categorical_accuracy: 0.6236\n",
      "Epoch 210/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6366 - sparse_categorical_accuracy: 0.6419 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.6271\n",
      "Epoch 211/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6365 - sparse_categorical_accuracy: 0.6403 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.6311\n",
      "Epoch 212/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.6407 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6421\n",
      "Epoch 213/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.6447 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.6307\n",
      "Epoch 214/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.6431 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.6346\n",
      "Epoch 215/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6330 - sparse_categorical_accuracy: 0.6450 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 216/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.6477 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.6316\n",
      "Epoch 217/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.6417 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.6368\n",
      "Epoch 218/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6311 - sparse_categorical_accuracy: 0.6481 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.6280\n",
      "Epoch 219/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6298 - sparse_categorical_accuracy: 0.6467 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.6192\n",
      "Epoch 220/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.6468 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.6355\n",
      "Epoch 221/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6261 - sparse_categorical_accuracy: 0.6509 - val_loss: 0.7192 - val_sparse_categorical_accuracy: 0.6188\n",
      "Epoch 222/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.6488 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.6267\n",
      "Epoch 223/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6281 - sparse_categorical_accuracy: 0.6495 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.6271\n",
      "Epoch 224/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.6255 - sparse_categorical_accuracy: 0.6549 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.6399\n",
      "Epoch 225/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6233 - sparse_categorical_accuracy: 0.6526 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.6236\n",
      "Epoch 226/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6245 - sparse_categorical_accuracy: 0.6499 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6360\n",
      "Epoch 227/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6232 - sparse_categorical_accuracy: 0.6510 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.6346\n",
      "Epoch 228/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.6243 - sparse_categorical_accuracy: 0.6509 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6448\n",
      "Epoch 229/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6234 - sparse_categorical_accuracy: 0.6500 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6364\n",
      "Epoch 230/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6234 - sparse_categorical_accuracy: 0.6522 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.6496\n",
      "Epoch 231/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6187 - sparse_categorical_accuracy: 0.6578 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.6324\n",
      "Epoch 232/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6213 - sparse_categorical_accuracy: 0.6557 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 233/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6180 - sparse_categorical_accuracy: 0.6561 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.6377\n",
      "Epoch 234/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6180 - sparse_categorical_accuracy: 0.6564 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6470\n",
      "Epoch 235/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.6152 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 236/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6174 - sparse_categorical_accuracy: 0.6579 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 237/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6153 - sparse_categorical_accuracy: 0.6573 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6457\n",
      "Epoch 238/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6139 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.6479\n",
      "Epoch 239/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6151 - sparse_categorical_accuracy: 0.6579 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.6593\n",
      "Epoch 240/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6152 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6496\n",
      "Epoch 241/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6110 - sparse_categorical_accuracy: 0.6614 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.6452\n",
      "Epoch 242/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6112 - sparse_categorical_accuracy: 0.6624 - val_loss: 0.6874 - val_sparse_categorical_accuracy: 0.6571\n",
      "Epoch 243/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6118 - sparse_categorical_accuracy: 0.6617 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.6567\n",
      "Epoch 244/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6092 - sparse_categorical_accuracy: 0.6603 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.6523\n",
      "Epoch 245/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6093 - sparse_categorical_accuracy: 0.6618 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.6602\n",
      "Epoch 246/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6075 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.6483\n",
      "Epoch 247/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6098 - sparse_categorical_accuracy: 0.6640 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.6413\n",
      "Epoch 248/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6064 - sparse_categorical_accuracy: 0.6658 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.6523\n",
      "Epoch 249/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6056 - sparse_categorical_accuracy: 0.6639 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.6483\n",
      "Epoch 250/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6044 - sparse_categorical_accuracy: 0.6620 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.6448\n",
      "Epoch 251/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6068 - sparse_categorical_accuracy: 0.6669 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.6505\n",
      "Epoch 252/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6037 - sparse_categorical_accuracy: 0.6641 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.6439\n",
      "Epoch 253/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6009 - sparse_categorical_accuracy: 0.6715 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6593\n",
      "Epoch 254/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.6028 - sparse_categorical_accuracy: 0.6678 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6496\n",
      "Epoch 255/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6019 - sparse_categorical_accuracy: 0.6692 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.6457\n",
      "Epoch 256/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6000 - sparse_categorical_accuracy: 0.6682 - val_loss: 0.7201 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 257/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6019 - sparse_categorical_accuracy: 0.6691 - val_loss: 0.6976 - val_sparse_categorical_accuracy: 0.6523\n",
      "Epoch 258/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5990 - sparse_categorical_accuracy: 0.6715 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.6523\n",
      "Epoch 259/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.6002 - sparse_categorical_accuracy: 0.6717 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6558\n",
      "Epoch 260/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5972 - sparse_categorical_accuracy: 0.6721 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.6461\n",
      "Epoch 261/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5974 - sparse_categorical_accuracy: 0.6702 - val_loss: 0.7059 - val_sparse_categorical_accuracy: 0.6320\n",
      "Epoch 262/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5956 - sparse_categorical_accuracy: 0.6756 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.6540\n",
      "Epoch 263/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5982 - sparse_categorical_accuracy: 0.6702 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6536\n",
      "Epoch 264/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5945 - sparse_categorical_accuracy: 0.6746 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 265/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5934 - sparse_categorical_accuracy: 0.6717 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6651\n",
      "Epoch 266/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5908 - sparse_categorical_accuracy: 0.6748 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.6492\n",
      "Epoch 267/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5915 - sparse_categorical_accuracy: 0.6777 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6527\n",
      "Epoch 268/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5905 - sparse_categorical_accuracy: 0.6772 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.6598\n",
      "Epoch 269/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5912 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.6501\n",
      "Epoch 270/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5939 - sparse_categorical_accuracy: 0.6735 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.6554\n",
      "Epoch 271/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5880 - sparse_categorical_accuracy: 0.6786 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.6681\n",
      "Epoch 272/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5882 - sparse_categorical_accuracy: 0.6773 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.6558\n",
      "Epoch 273/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5865 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 274/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5884 - sparse_categorical_accuracy: 0.6784 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.6518\n",
      "Epoch 275/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5852 - sparse_categorical_accuracy: 0.6808 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.6452\n",
      "Epoch 276/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5867 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6615\n",
      "Epoch 277/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5865 - sparse_categorical_accuracy: 0.6838 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6580\n",
      "Epoch 278/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5846 - sparse_categorical_accuracy: 0.6797 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.6593\n",
      "Epoch 279/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5835 - sparse_categorical_accuracy: 0.6812 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.6659\n",
      "Epoch 280/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5821 - sparse_categorical_accuracy: 0.6842 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.6699\n",
      "Epoch 281/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5784 - sparse_categorical_accuracy: 0.6846 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6651\n",
      "Epoch 282/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5826 - sparse_categorical_accuracy: 0.6845 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6470\n",
      "Epoch 283/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5806 - sparse_categorical_accuracy: 0.6834 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.6712\n",
      "Epoch 284/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5772 - sparse_categorical_accuracy: 0.6844 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6695\n",
      "Epoch 285/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5775 - sparse_categorical_accuracy: 0.6871 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.6699\n",
      "Epoch 286/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5755 - sparse_categorical_accuracy: 0.6842 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.6501\n",
      "Epoch 287/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5761 - sparse_categorical_accuracy: 0.6864 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6708\n",
      "Epoch 288/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5765 - sparse_categorical_accuracy: 0.6877 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.6606\n",
      "Epoch 289/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5769 - sparse_categorical_accuracy: 0.6834 - val_loss: 0.6815 - val_sparse_categorical_accuracy: 0.6659\n",
      "Epoch 290/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5751 - sparse_categorical_accuracy: 0.6877 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 291/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.6677\n",
      "Epoch 292/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.6873 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.6615\n",
      "Epoch 293/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5721 - sparse_categorical_accuracy: 0.6879 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 294/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5725 - sparse_categorical_accuracy: 0.6905 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.6796\n",
      "Epoch 295/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.6917 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 296/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.6899 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6822\n",
      "Epoch 297/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5722 - sparse_categorical_accuracy: 0.6871 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.6576\n",
      "Epoch 298/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.6549\n",
      "Epoch 299/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.6929 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6725\n",
      "Epoch 300/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5691 - sparse_categorical_accuracy: 0.6909 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.6673\n",
      "Epoch 301/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5690 - sparse_categorical_accuracy: 0.6923 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.6673\n",
      "Epoch 302/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5633 - sparse_categorical_accuracy: 0.6960 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.6765\n",
      "Epoch 303/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5657 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6770\n",
      "Epoch 304/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.6965 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6893\n",
      "Epoch 305/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5640 - sparse_categorical_accuracy: 0.6919 - val_loss: 0.6690 - val_sparse_categorical_accuracy: 0.6827\n",
      "Epoch 306/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5605 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.7208 - val_sparse_categorical_accuracy: 0.6549\n",
      "Epoch 307/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5617 - sparse_categorical_accuracy: 0.6988 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 308/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.7020 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6831\n",
      "Epoch 309/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.6970 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 310/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.6668\n",
      "Epoch 311/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5599 - sparse_categorical_accuracy: 0.7008 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 312/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5559 - sparse_categorical_accuracy: 0.7035 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6809\n",
      "Epoch 313/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5542 - sparse_categorical_accuracy: 0.7007 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 314/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5576 - sparse_categorical_accuracy: 0.7027 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6730\n",
      "Epoch 315/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5567 - sparse_categorical_accuracy: 0.7030 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.6831\n",
      "Epoch 316/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5515 - sparse_categorical_accuracy: 0.7030 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6792\n",
      "Epoch 317/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5543 - sparse_categorical_accuracy: 0.7028 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 318/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.7052 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6708\n",
      "Epoch 319/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5570 - sparse_categorical_accuracy: 0.7001 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 320/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6871\n",
      "Epoch 321/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6796\n",
      "Epoch 322/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.7031 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.6770\n",
      "Epoch 323/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5455 - sparse_categorical_accuracy: 0.7113 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6765\n",
      "Epoch 324/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.7073 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6822\n",
      "Epoch 325/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5517 - sparse_categorical_accuracy: 0.7047 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.6770\n",
      "Epoch 326/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5475 - sparse_categorical_accuracy: 0.7086 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6778\n",
      "Epoch 327/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5469 - sparse_categorical_accuracy: 0.7075 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 328/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5431 - sparse_categorical_accuracy: 0.7100 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6778\n",
      "Epoch 329/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5427 - sparse_categorical_accuracy: 0.7106 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.6875\n",
      "Epoch 330/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5439 - sparse_categorical_accuracy: 0.7091 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6862\n",
      "Epoch 331/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5428 - sparse_categorical_accuracy: 0.7108 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.6752\n",
      "Epoch 332/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.7049 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.6814\n",
      "Epoch 333/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5413 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6655\n",
      "Epoch 334/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5441 - sparse_categorical_accuracy: 0.7073 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6734\n",
      "Epoch 335/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5407 - sparse_categorical_accuracy: 0.7142 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6924\n",
      "Epoch 336/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5373 - sparse_categorical_accuracy: 0.7139 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6924\n",
      "Epoch 337/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5376 - sparse_categorical_accuracy: 0.7101 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.6699\n",
      "Epoch 338/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5406 - sparse_categorical_accuracy: 0.7131 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.6844\n",
      "Epoch 339/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5400 - sparse_categorical_accuracy: 0.7118 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.6787\n",
      "Epoch 340/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5384 - sparse_categorical_accuracy: 0.7144 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6897\n",
      "Epoch 341/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5359 - sparse_categorical_accuracy: 0.7128 - val_loss: 0.6669 - val_sparse_categorical_accuracy: 0.6937\n",
      "Epoch 342/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5345 - sparse_categorical_accuracy: 0.7171 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6915\n",
      "Epoch 343/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5354 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6884\n",
      "Epoch 344/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5371 - sparse_categorical_accuracy: 0.7154 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.6893\n",
      "Epoch 345/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5314 - sparse_categorical_accuracy: 0.7153 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6937\n",
      "Epoch 346/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5325 - sparse_categorical_accuracy: 0.7153 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6858\n",
      "Epoch 347/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.7151 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6906\n",
      "Epoch 348/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5368 - sparse_categorical_accuracy: 0.7149 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.6818\n",
      "Epoch 349/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5291 - sparse_categorical_accuracy: 0.7200 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.6853\n",
      "Epoch 350/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5307 - sparse_categorical_accuracy: 0.7173 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6985\n",
      "Epoch 351/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5283 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.6963\n",
      "Epoch 352/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5312 - sparse_categorical_accuracy: 0.7194 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6880\n",
      "Epoch 353/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5266 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6981\n",
      "Epoch 354/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5257 - sparse_categorical_accuracy: 0.7215 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6897\n",
      "Epoch 355/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5269 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.6682 - val_sparse_categorical_accuracy: 0.6902\n",
      "Epoch 356/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5261 - sparse_categorical_accuracy: 0.7189 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.6941\n",
      "Epoch 357/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5257 - sparse_categorical_accuracy: 0.7253 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.7144\n",
      "Epoch 358/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5245 - sparse_categorical_accuracy: 0.7267 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6950\n",
      "Epoch 359/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5220 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.6985\n",
      "Epoch 360/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5229 - sparse_categorical_accuracy: 0.7221 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.6822\n",
      "Epoch 361/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5228 - sparse_categorical_accuracy: 0.7263 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6950\n",
      "Epoch 362/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5217 - sparse_categorical_accuracy: 0.7233 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.6836\n",
      "Epoch 363/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5170 - sparse_categorical_accuracy: 0.7306 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.6783\n",
      "Epoch 364/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5232 - sparse_categorical_accuracy: 0.7244 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6941\n",
      "Epoch 365/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5163 - sparse_categorical_accuracy: 0.7284 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.7078\n",
      "Epoch 366/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5221 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.7016\n",
      "Epoch 367/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5183 - sparse_categorical_accuracy: 0.7284 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6941\n",
      "Epoch 368/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5149 - sparse_categorical_accuracy: 0.7281 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.7007\n",
      "Epoch 369/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5130 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6853\n",
      "Epoch 370/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5163 - sparse_categorical_accuracy: 0.7284 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6924\n",
      "Epoch 371/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5151 - sparse_categorical_accuracy: 0.7302 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.6880\n",
      "Epoch 372/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5145 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6977\n",
      "Epoch 373/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5167 - sparse_categorical_accuracy: 0.7293 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.6955\n",
      "Epoch 374/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5088 - sparse_categorical_accuracy: 0.7340 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.7043\n",
      "Epoch 375/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5105 - sparse_categorical_accuracy: 0.7305 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.7007\n",
      "Epoch 376/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5163 - sparse_categorical_accuracy: 0.7260 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.6933\n",
      "Epoch 377/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5135 - sparse_categorical_accuracy: 0.7302 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6928\n",
      "Epoch 378/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5077 - sparse_categorical_accuracy: 0.7353 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6968\n",
      "Epoch 379/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.5107 - sparse_categorical_accuracy: 0.7348 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6928\n",
      "Epoch 380/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5074 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6651 - val_sparse_categorical_accuracy: 0.7091\n",
      "Epoch 381/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5082 - sparse_categorical_accuracy: 0.7326 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.7113\n",
      "Epoch 382/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5086 - sparse_categorical_accuracy: 0.7340 - val_loss: 0.6828 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 383/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5073 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6928\n",
      "Epoch 384/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5038 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.7021\n",
      "Epoch 385/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5068 - sparse_categorical_accuracy: 0.7345 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.7043\n",
      "Epoch 386/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5059 - sparse_categorical_accuracy: 0.7358 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.7034\n",
      "Epoch 387/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5083 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6818 - val_sparse_categorical_accuracy: 0.6999\n",
      "Epoch 388/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5068 - sparse_categorical_accuracy: 0.7363 - val_loss: 0.6623 - val_sparse_categorical_accuracy: 0.7149\n",
      "Epoch 389/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5012 - sparse_categorical_accuracy: 0.7374 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 390/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5018 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.7179\n",
      "Epoch 391/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5008 - sparse_categorical_accuracy: 0.7364 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.7052\n",
      "Epoch 392/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4988 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.7135\n",
      "Epoch 393/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5021 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.7074\n",
      "Epoch 394/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6963\n",
      "Epoch 395/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4983 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.7065\n",
      "Epoch 396/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4956 - sparse_categorical_accuracy: 0.7426 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.7113\n",
      "Epoch 397/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4987 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.7193\n",
      "Epoch 398/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4979 - sparse_categorical_accuracy: 0.7413 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.7021\n",
      "Epoch 399/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.5004 - sparse_categorical_accuracy: 0.7363 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.7069\n",
      "Epoch 400/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4970 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.7003\n",
      "Epoch 401/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4911 - sparse_categorical_accuracy: 0.7433 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 402/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4923 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.7087\n",
      "Epoch 403/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.7473 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.7056\n",
      "Epoch 404/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4910 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.6933\n",
      "Epoch 405/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4931 - sparse_categorical_accuracy: 0.7446 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.6941\n",
      "Epoch 406/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4906 - sparse_categorical_accuracy: 0.7459 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.7131\n",
      "Epoch 407/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.7078\n",
      "Epoch 408/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4907 - sparse_categorical_accuracy: 0.7444 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.7104\n",
      "Epoch 409/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4923 - sparse_categorical_accuracy: 0.7435 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.7193\n",
      "Epoch 410/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4856 - sparse_categorical_accuracy: 0.7497 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.7215\n",
      "Epoch 411/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4842 - sparse_categorical_accuracy: 0.7506 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.7228\n",
      "Epoch 412/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4879 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.7206\n",
      "Epoch 413/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4856 - sparse_categorical_accuracy: 0.7481 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.7281\n",
      "Epoch 414/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4832 - sparse_categorical_accuracy: 0.7509 - val_loss: 0.6819 - val_sparse_categorical_accuracy: 0.7144\n",
      "Epoch 415/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4832 - sparse_categorical_accuracy: 0.7493 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.7069\n",
      "Epoch 416/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4851 - sparse_categorical_accuracy: 0.7483 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 417/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4856 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.7210\n",
      "Epoch 418/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4821 - sparse_categorical_accuracy: 0.7511 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.7241\n",
      "Epoch 419/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4818 - sparse_categorical_accuracy: 0.7491 - val_loss: 0.6500 - val_sparse_categorical_accuracy: 0.7223\n",
      "Epoch 420/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4872 - sparse_categorical_accuracy: 0.7473 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.7223\n",
      "Epoch 421/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4851 - sparse_categorical_accuracy: 0.7483 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.7144\n",
      "Epoch 422/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4774 - sparse_categorical_accuracy: 0.7541 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.7118\n",
      "Epoch 423/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4775 - sparse_categorical_accuracy: 0.7514 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 424/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4830 - sparse_categorical_accuracy: 0.7521 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.7091\n",
      "Epoch 425/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4800 - sparse_categorical_accuracy: 0.7524 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.7193\n",
      "Epoch 426/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4774 - sparse_categorical_accuracy: 0.7549 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.7338\n",
      "Epoch 427/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4788 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.7223\n",
      "Epoch 428/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4765 - sparse_categorical_accuracy: 0.7497 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.7126\n",
      "Epoch 429/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4763 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.7087\n",
      "Epoch 430/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4827 - sparse_categorical_accuracy: 0.7512 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.7219\n",
      "Epoch 431/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4719 - sparse_categorical_accuracy: 0.7566 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.7140\n",
      "Epoch 432/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4725 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.7078\n",
      "Epoch 433/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4776 - sparse_categorical_accuracy: 0.7510 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.6999\n",
      "Epoch 434/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4698 - sparse_categorical_accuracy: 0.7595 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.7144\n",
      "Epoch 435/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4681 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6682 - val_sparse_categorical_accuracy: 0.7307\n",
      "Epoch 436/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4771 - sparse_categorical_accuracy: 0.7559 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.7122\n",
      "Epoch 437/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4723 - sparse_categorical_accuracy: 0.7577 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.7303\n",
      "Epoch 438/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4677 - sparse_categorical_accuracy: 0.7641 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.7184\n",
      "Epoch 439/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4738 - sparse_categorical_accuracy: 0.7539 - val_loss: 0.6698 - val_sparse_categorical_accuracy: 0.7223\n",
      "Epoch 440/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.7571 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.7135\n",
      "Epoch 441/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4712 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.7171\n",
      "Epoch 442/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.7601 - val_loss: 0.6819 - val_sparse_categorical_accuracy: 0.7162\n",
      "Epoch 443/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4695 - sparse_categorical_accuracy: 0.7571 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.7118\n",
      "Epoch 444/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4611 - sparse_categorical_accuracy: 0.7644 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.7237\n",
      "Epoch 445/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4716 - sparse_categorical_accuracy: 0.7559 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.7263\n",
      "Epoch 446/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4686 - sparse_categorical_accuracy: 0.7619 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.7091\n",
      "Epoch 447/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4675 - sparse_categorical_accuracy: 0.7612 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.7364\n",
      "Epoch 448/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4621 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.7166\n",
      "Epoch 449/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4634 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.7140\n",
      "Epoch 450/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4641 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.6628 - val_sparse_categorical_accuracy: 0.7241\n",
      "Epoch 451/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4687 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.7245\n",
      "Epoch 452/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.7640 - val_loss: 0.7183 - val_sparse_categorical_accuracy: 0.7069\n",
      "Epoch 453/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4617 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.7378\n",
      "Epoch 454/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4578 - sparse_categorical_accuracy: 0.7644 - val_loss: 0.7139 - val_sparse_categorical_accuracy: 0.7047\n",
      "Epoch 455/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4595 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.7391\n",
      "Epoch 456/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4573 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.7144\n",
      "Epoch 457/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4546 - sparse_categorical_accuracy: 0.7664 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.7166\n",
      "Epoch 458/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4678 - sparse_categorical_accuracy: 0.7597 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.7162\n",
      "Epoch 459/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.7673 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.7373\n",
      "Epoch 460/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4593 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.7404\n",
      "Epoch 461/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4517 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.7197\n",
      "Epoch 462/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4581 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.7290\n",
      "Epoch 463/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.7714 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.7157\n",
      "Epoch 464/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4538 - sparse_categorical_accuracy: 0.7673 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.7298\n",
      "Epoch 465/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.7693 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.7122\n",
      "Epoch 466/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7660 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.7254\n",
      "Epoch 467/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4527 - sparse_categorical_accuracy: 0.7669 - val_loss: 0.7171 - val_sparse_categorical_accuracy: 0.7219\n",
      "Epoch 468/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4530 - sparse_categorical_accuracy: 0.7708 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 469/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4637 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.7285 - val_sparse_categorical_accuracy: 0.7316\n",
      "Epoch 470/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4606 - sparse_categorical_accuracy: 0.7626 - val_loss: 0.7327 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 471/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4511 - sparse_categorical_accuracy: 0.7709 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.7140\n",
      "Epoch 472/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4455 - sparse_categorical_accuracy: 0.7741 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.7373\n",
      "Epoch 473/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4478 - sparse_categorical_accuracy: 0.7741 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.7219\n",
      "Epoch 474/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4471 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.7259\n",
      "Epoch 475/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4465 - sparse_categorical_accuracy: 0.7740 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.7294\n",
      "Epoch 476/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4461 - sparse_categorical_accuracy: 0.7771 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.7338\n",
      "Epoch 477/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4452 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.7404\n",
      "Epoch 478/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.7719 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.7259\n",
      "Epoch 479/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.7744 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.7422\n",
      "Epoch 480/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4451 - sparse_categorical_accuracy: 0.7732 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.7303\n",
      "Epoch 481/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4451 - sparse_categorical_accuracy: 0.7762 - val_loss: 0.6603 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 482/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.7709 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.7245\n",
      "Epoch 483/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.7369\n",
      "Epoch 484/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4487 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.7197\n",
      "Epoch 485/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4477 - sparse_categorical_accuracy: 0.7742 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.7395\n",
      "Epoch 486/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4371 - sparse_categorical_accuracy: 0.7805 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.7338\n",
      "Epoch 487/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4441 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.7307\n",
      "Epoch 488/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4422 - sparse_categorical_accuracy: 0.7782 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.7268\n",
      "Epoch 489/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4403 - sparse_categorical_accuracy: 0.7744 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.7325\n",
      "Epoch 490/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4468 - sparse_categorical_accuracy: 0.7743 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.7320\n",
      "Epoch 491/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4375 - sparse_categorical_accuracy: 0.7774 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 492/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4378 - sparse_categorical_accuracy: 0.7783 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.7356\n",
      "Epoch 493/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4386 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.6826 - val_sparse_categorical_accuracy: 0.7431\n",
      "Epoch 494/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4380 - sparse_categorical_accuracy: 0.7792 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.7184\n",
      "Epoch 495/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4413 - sparse_categorical_accuracy: 0.7766 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.7237\n",
      "Epoch 496/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4432 - sparse_categorical_accuracy: 0.7748 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.7435\n",
      "Epoch 497/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4301 - sparse_categorical_accuracy: 0.7856 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.7409\n",
      "Epoch 498/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4305 - sparse_categorical_accuracy: 0.7863 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.7316\n",
      "Epoch 499/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.7439\n",
      "Epoch 500/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4347 - sparse_categorical_accuracy: 0.7805 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.7303\n",
      "Epoch 501/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4378 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.7435\n",
      "Epoch 502/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4381 - sparse_categorical_accuracy: 0.7806 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.7228\n",
      "Epoch 503/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.7822 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.7461\n",
      "Epoch 504/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4305 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.7320\n",
      "Epoch 505/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4267 - sparse_categorical_accuracy: 0.7873 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.7325\n",
      "Epoch 506/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.7804 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.7320\n",
      "Epoch 507/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4253 - sparse_categorical_accuracy: 0.7855 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.7351\n",
      "Epoch 508/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4328 - sparse_categorical_accuracy: 0.7784 - val_loss: 0.7065 - val_sparse_categorical_accuracy: 0.7409\n",
      "Epoch 509/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4406 - sparse_categorical_accuracy: 0.7776 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.7417\n",
      "Epoch 510/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 511/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4222 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.7567\n",
      "Epoch 512/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4207 - sparse_categorical_accuracy: 0.7898 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.7259\n",
      "Epoch 513/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4305 - sparse_categorical_accuracy: 0.7826 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.7312\n",
      "Epoch 514/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4268 - sparse_categorical_accuracy: 0.7854 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.7294\n",
      "Epoch 515/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4319 - sparse_categorical_accuracy: 0.7843 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.7382\n",
      "Epoch 516/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4248 - sparse_categorical_accuracy: 0.7843 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.7395\n",
      "Epoch 517/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4267 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.7285\n",
      "Epoch 518/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4195 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.7510\n",
      "Epoch 519/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.7528\n",
      "Epoch 520/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.7875 - val_loss: 0.6832 - val_sparse_categorical_accuracy: 0.7422\n",
      "Epoch 521/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4232 - sparse_categorical_accuracy: 0.7847 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.7523\n",
      "Epoch 522/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4229 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.7457\n",
      "Epoch 523/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4203 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.7550\n",
      "Epoch 524/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.7853 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.7364\n",
      "Epoch 525/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4275 - sparse_categorical_accuracy: 0.7852 - val_loss: 0.7022 - val_sparse_categorical_accuracy: 0.7523\n",
      "Epoch 526/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4127 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.7488\n",
      "Epoch 527/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4141 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.7417\n",
      "Epoch 528/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4411 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.6874 - val_sparse_categorical_accuracy: 0.7545\n",
      "Epoch 529/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4144 - sparse_categorical_accuracy: 0.7909 - val_loss: 0.7444 - val_sparse_categorical_accuracy: 0.7382\n",
      "Epoch 530/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4179 - sparse_categorical_accuracy: 0.7906 - val_loss: 0.7139 - val_sparse_categorical_accuracy: 0.7298\n",
      "Epoch 531/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4178 - sparse_categorical_accuracy: 0.7897 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.7439\n",
      "Epoch 532/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4142 - sparse_categorical_accuracy: 0.7896 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.7572\n",
      "Epoch 533/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4255 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.7176 - val_sparse_categorical_accuracy: 0.7444\n",
      "Epoch 534/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4119 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.7532\n",
      "Epoch 535/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4155 - sparse_categorical_accuracy: 0.7924 - val_loss: 0.7192 - val_sparse_categorical_accuracy: 0.7290\n",
      "Epoch 536/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4156 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.7508 - val_sparse_categorical_accuracy: 0.7135\n",
      "Epoch 537/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4170 - sparse_categorical_accuracy: 0.7925 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.7448\n",
      "Epoch 538/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4125 - sparse_categorical_accuracy: 0.7925 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.7448\n",
      "Epoch 539/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4207 - sparse_categorical_accuracy: 0.7918 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 540/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4171 - sparse_categorical_accuracy: 0.7907 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.7602\n",
      "Epoch 541/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4175 - sparse_categorical_accuracy: 0.7958 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.7351\n",
      "Epoch 542/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4074 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.7532\n",
      "Epoch 543/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4081 - sparse_categorical_accuracy: 0.7958 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.7444\n",
      "Epoch 544/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4159 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.6566 - val_sparse_categorical_accuracy: 0.7651\n",
      "Epoch 545/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4119 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.7378\n",
      "Epoch 546/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4126 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.7510\n",
      "Epoch 547/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4096 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.7409\n",
      "Epoch 548/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.4042 - sparse_categorical_accuracy: 0.8004 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.7695\n",
      "Epoch 549/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4091 - sparse_categorical_accuracy: 0.7919 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.7554\n",
      "Epoch 550/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.7146 - val_sparse_categorical_accuracy: 0.7364\n",
      "Epoch 551/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4149 - sparse_categorical_accuracy: 0.7947 - val_loss: 0.7059 - val_sparse_categorical_accuracy: 0.7382\n",
      "Epoch 552/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4005 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.7536\n",
      "Epoch 553/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4079 - sparse_categorical_accuracy: 0.7957 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.7387\n",
      "Epoch 554/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4120 - sparse_categorical_accuracy: 0.7936 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.7448\n",
      "Epoch 555/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4080 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.7146 - val_sparse_categorical_accuracy: 0.7453\n",
      "Epoch 556/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4155 - sparse_categorical_accuracy: 0.7945 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.7550\n",
      "Epoch 557/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4130 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.7431\n",
      "Epoch 558/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4023 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.7602\n",
      "Epoch 559/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4055 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.7519\n",
      "Epoch 560/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4016 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.7461\n",
      "Epoch 561/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4072 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.7220 - val_sparse_categorical_accuracy: 0.7506\n",
      "Epoch 562/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4026 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.7461\n",
      "Epoch 563/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3987 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.7439\n",
      "Epoch 564/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4058 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.7228 - val_sparse_categorical_accuracy: 0.7475\n",
      "Epoch 565/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3940 - sparse_categorical_accuracy: 0.8051 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 566/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3989 - sparse_categorical_accuracy: 0.8016 - val_loss: 0.7029 - val_sparse_categorical_accuracy: 0.7506\n",
      "Epoch 567/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4067 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.7053 - val_sparse_categorical_accuracy: 0.7373\n",
      "Epoch 568/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4010 - sparse_categorical_accuracy: 0.7985 - val_loss: 0.6822 - val_sparse_categorical_accuracy: 0.7629\n",
      "Epoch 569/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3922 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.7219 - val_sparse_categorical_accuracy: 0.7589\n",
      "Epoch 570/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4104 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.7461\n",
      "Epoch 571/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4034 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.7479\n",
      "Epoch 572/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3929 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.7234 - val_sparse_categorical_accuracy: 0.7475\n",
      "Epoch 573/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3921 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.7677\n",
      "Epoch 574/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3942 - sparse_categorical_accuracy: 0.8016 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.7497\n",
      "Epoch 575/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4010 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.6968 - val_sparse_categorical_accuracy: 0.7629\n",
      "Epoch 576/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3942 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.7288 - val_sparse_categorical_accuracy: 0.7492\n",
      "Epoch 577/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3891 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.7602\n",
      "Epoch 578/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3931 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.7686\n",
      "Epoch 579/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3938 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.7486 - val_sparse_categorical_accuracy: 0.7497\n",
      "Epoch 580/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4084 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.7187 - val_sparse_categorical_accuracy: 0.7506\n",
      "Epoch 581/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3899 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.7669\n",
      "Epoch 582/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3897 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.7256 - val_sparse_categorical_accuracy: 0.7479\n",
      "Epoch 583/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3997 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.7594\n",
      "Epoch 584/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3874 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.7616\n",
      "Epoch 585/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3895 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.7222 - val_sparse_categorical_accuracy: 0.7576\n",
      "Epoch 586/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3931 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.7602\n",
      "Epoch 587/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3914 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.7218 - val_sparse_categorical_accuracy: 0.7611\n",
      "Epoch 588/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3953 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.7099 - val_sparse_categorical_accuracy: 0.7607\n",
      "Epoch 589/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3862 - sparse_categorical_accuracy: 0.8057 - val_loss: 0.7216 - val_sparse_categorical_accuracy: 0.7616\n",
      "Epoch 590/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3889 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.7642\n",
      "Epoch 591/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.4056 - sparse_categorical_accuracy: 0.8018 - val_loss: 0.7326 - val_sparse_categorical_accuracy: 0.7457\n",
      "Epoch 592/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3892 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.7397 - val_sparse_categorical_accuracy: 0.7541\n",
      "Epoch 593/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3945 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.7594\n",
      "Epoch 594/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3883 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.7200 - val_sparse_categorical_accuracy: 0.7594\n",
      "Epoch 595/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3795 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.7642\n",
      "Epoch 596/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3875 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.7633\n",
      "Epoch 597/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3931 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.7589\n",
      "Epoch 598/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3827 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.7558\n",
      "Epoch 599/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3886 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.7414 - val_sparse_categorical_accuracy: 0.7567\n",
      "Epoch 600/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3935 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.7572\n",
      "Epoch 601/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3885 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.7660\n",
      "Epoch 602/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3836 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.7576\n",
      "Epoch 603/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3762 - sparse_categorical_accuracy: 0.8139 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.7704\n",
      "Epoch 604/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.8116 - val_loss: 0.7443 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 605/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3839 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.7189 - val_sparse_categorical_accuracy: 0.7558\n",
      "Epoch 606/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3826 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.7625 - val_sparse_categorical_accuracy: 0.7572\n",
      "Epoch 607/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3803 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.7669\n",
      "Epoch 608/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3810 - sparse_categorical_accuracy: 0.8133 - val_loss: 0.7357 - val_sparse_categorical_accuracy: 0.7572\n",
      "Epoch 609/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3858 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.7673\n",
      "Epoch 610/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3825 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.7457 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 611/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3846 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.7735\n",
      "Epoch 612/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3790 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.7550\n",
      "Epoch 613/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3767 - sparse_categorical_accuracy: 0.8136 - val_loss: 0.7393 - val_sparse_categorical_accuracy: 0.7611\n",
      "Epoch 614/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3768 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.7769 - val_sparse_categorical_accuracy: 0.7413\n",
      "Epoch 615/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3822 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 616/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3764 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.7308 - val_sparse_categorical_accuracy: 0.7554\n",
      "Epoch 617/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3880 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.7406 - val_sparse_categorical_accuracy: 0.7576\n",
      "Epoch 618/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3742 - sparse_categorical_accuracy: 0.8168 - val_loss: 0.7167 - val_sparse_categorical_accuracy: 0.7673\n",
      "Epoch 619/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3786 - sparse_categorical_accuracy: 0.8144 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.7726\n",
      "Epoch 620/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.7270 - val_sparse_categorical_accuracy: 0.7664\n",
      "Epoch 621/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.7332 - val_sparse_categorical_accuracy: 0.7686\n",
      "Epoch 622/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3813 - sparse_categorical_accuracy: 0.8130 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.7523\n",
      "Epoch 623/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3761 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.7362 - val_sparse_categorical_accuracy: 0.7743\n",
      "Epoch 624/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3786 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.7186 - val_sparse_categorical_accuracy: 0.7633\n",
      "Epoch 625/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3682 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.7739\n",
      "Epoch 626/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3700 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.7134 - val_sparse_categorical_accuracy: 0.7686\n",
      "Epoch 627/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3783 - sparse_categorical_accuracy: 0.8128 - val_loss: 0.7530 - val_sparse_categorical_accuracy: 0.7620\n",
      "Epoch 628/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3739 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.7664\n",
      "Epoch 629/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3702 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.7482 - val_sparse_categorical_accuracy: 0.7660\n",
      "Epoch 630/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3732 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.7660 - val_sparse_categorical_accuracy: 0.7651\n",
      "Epoch 631/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3894 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.7347 - val_sparse_categorical_accuracy: 0.7607\n",
      "Epoch 632/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3683 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.7194 - val_sparse_categorical_accuracy: 0.7774\n",
      "Epoch 633/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.7502 - val_sparse_categorical_accuracy: 0.7576\n",
      "Epoch 634/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3618 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.7348 - val_sparse_categorical_accuracy: 0.7655\n",
      "Epoch 635/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3685 - sparse_categorical_accuracy: 0.8209 - val_loss: 0.7243 - val_sparse_categorical_accuracy: 0.7686\n",
      "Epoch 636/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3750 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.7286 - val_sparse_categorical_accuracy: 0.7845\n",
      "Epoch 637/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.7435 - val_sparse_categorical_accuracy: 0.7655\n",
      "Epoch 638/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3759 - sparse_categorical_accuracy: 0.8149 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.7572\n",
      "Epoch 639/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3689 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.7642\n",
      "Epoch 640/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3698 - sparse_categorical_accuracy: 0.8171 - val_loss: 0.7297 - val_sparse_categorical_accuracy: 0.7651\n",
      "Epoch 641/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3662 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.7690 - val_sparse_categorical_accuracy: 0.7620\n",
      "Epoch 642/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3689 - sparse_categorical_accuracy: 0.8207 - val_loss: 0.7570 - val_sparse_categorical_accuracy: 0.7651\n",
      "Epoch 643/800\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.3682 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.7656 - val_sparse_categorical_accuracy: 0.7501\n",
      "Epoch 644/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3710 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.7712 - val_sparse_categorical_accuracy: 0.7576\n",
      "Epoch 645/800\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8150 - val_loss: 0.7385 - val_sparse_categorical_accuracy: 0.7673\n",
      "Epoch 646/800\n",
      "377/568 [==================>...........] - ETA: 0s - loss: 0.3636 - sparse_categorical_accuracy: 0.8254"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_56460/3489126263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Correr o treino, indica as features as labels e o número de épocas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willian\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 _r=1):\n\u001b[0;32m   1177\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willian\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willian\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willian\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willian\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\willian\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willian\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Correr o treino, indica as features as labels e o número de épocas\n",
    "history = model.fit(train_features, train_labels, epochs=800,validation_data=(valid_features,valid_labels))\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad56cb3-f20b-4812-85ae-8a705e02b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correr no conjunto teste (com o que foi treinado) e obter o resultado\n",
    "test = model.evaluate(test_features,test_labels)\n",
    "print(\"Teste:\\n\",test)\n",
    "loss,acc = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80949ab7-2e22-4895-9aa3-9db044730707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver um plot dos resultados de treino e teste \n",
    "# coloquei também o valor do teste, mas esse é só um ponto no final\n",
    "# place a text box in upper left in axes coords\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(0.3, 0.90, \"Acc on test: %.2f\" % acc,  fontsize=14, transform=plt.axes().transAxes, \n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77804a-b7a7-4bec-bce5-a55aa45962dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
