{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9bd817-e8ed-43e7-8398-9e8a4b08d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a91643-49c2-437a-8887-2d14bede0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição da seed do python\n",
    "seed(1)\n",
    "# e seed do tensorflow\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f101b42a-2767-4501-a9c5-bc77b1a4e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição do ficheiro de dados (treino/validação)\n",
    "# symbol = 'ada'\n",
    "crypto_ta_dataset_fp = \"datasets/crypto_ta_btc_04.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0f0508-67cf-4501-bb3a-bca61e3e2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das classses\n",
    "# class_names = ['Very Low', 'Low', 'High', 'Very High']\n",
    "class_names = ['Very Low', 'Low', 'Very High', 'High', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721b9bc1-dcb8-4e66-831c-4d970bf21a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sma_200     ema_8    ema_20    ema_25    ema_30    ema_35    ema_40  \\\n",
      "0  0.255202 -0.409322  0.096394  0.133747  0.149948  0.156290  0.157773   \n",
      "1  0.257581 -0.093549  0.186353  0.203982  0.208116  0.206254  0.201748   \n",
      "2  0.268577  0.281311  0.323255  0.313902  0.300544  0.286328  0.272576   \n",
      "3  0.251986 -0.207606  0.105288  0.137413  0.152578  0.159120  0.161111   \n",
      "4  0.253124  0.069138  0.195859  0.208523  0.211550  0.209772  0.205674   \n",
      "\n",
      "     ema_45    ema_50   sma_vol       roc        cmo       ppo   linearreg  \\\n",
      "0  0.156829  0.154781  4.110956 -4.930363  11.508362  2.970577  462.048771   \n",
      "1  0.196209  0.190500  4.050205  1.032400  16.962188  3.053514  461.049000   \n",
      "2  0.259821  0.248303 -0.546236  1.598866  24.774405  3.250285  461.917400   \n",
      "3  0.160681  0.159050  0.473048 -1.897426  11.191402  3.361591  459.937457   \n",
      "4  0.200571  0.195222 -1.599098  1.046878  16.490509  3.398493  458.262343   \n",
      "\n",
      "          tsf    trend  \n",
      "0  464.956484  NEUTRAL  \n",
      "1  463.534231  NEUTRAL  \n",
      "2  464.243923  NEUTRAL  \n",
      "3  461.772978  NEUTRAL  \n",
      "4  459.570209  NEUTRAL  \n",
      "Features: Index(['sma_200', 'ema_8', 'ema_20', 'ema_25', 'ema_30', 'ema_35', 'ema_40',\n",
      "       'ema_45', 'ema_50', 'sma_vol', 'roc', 'cmo', 'ppo', 'linearreg', 'tsf'],\n",
      "      dtype='object')\n",
      "Label: trend\n"
     ]
    }
   ],
   "source": [
    "# ler o ficheiro de dados, indicando o ficheiro e indicamos os nomes das colunas (que não estão no ficheiro)\n",
    "crypto_ta_dataset = pd.read_csv(crypto_ta_dataset_fp)\n",
    "# remover as colunas que nao interessam\n",
    "# crypto_ta_dataset.drop('ema_25', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('ema_30', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('ema_35', axis=1, inplace=True)\n",
    "crypto_ta_dataset.drop('macd', axis=1, inplace=True)\n",
    "crypto_ta_dataset.drop('macdsignal', axis=1, inplace=True)\n",
    "crypto_ta_dataset.drop('macdhist', axis=1, inplace=True)\n",
    "# imprime um as primeiras linhas dos dados\n",
    "print(crypto_ta_dataset.head())\n",
    "\n",
    "# colunas que são features e coluna que é a label (a ultima neste caso)\n",
    "feature_names = crypto_ta_dataset.columns[:-1]\n",
    "label_name = crypto_ta_dataset.columns[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6f7ad5-57df-4355-a950-5933cbe63e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sma_200     ema_8    ema_20    ema_25    ema_30    ema_35    ema_40  \\\n",
      "0      0.255202 -0.409322  0.096394  0.133747  0.149948  0.156290  0.157773   \n",
      "1      0.257581 -0.093549  0.186353  0.203982  0.208116  0.206254  0.201748   \n",
      "2      0.268577  0.281311  0.323255  0.313902  0.300544  0.286328  0.272576   \n",
      "3      0.251986 -0.207606  0.105288  0.137413  0.152578  0.159120  0.161111   \n",
      "4      0.253124  0.069138  0.195859  0.208523  0.211550  0.209772  0.205674   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "22699  0.032951  0.045498  0.045542  0.049875  0.052914  0.054778  0.055799   \n",
      "22700  0.035429  0.116512  0.076056  0.074226  0.073174  0.072148  0.071024   \n",
      "22701  0.036673  0.156520  0.097136  0.091423  0.087691  0.084726  0.082141   \n",
      "22702  0.039982  0.306922  0.167543  0.148832  0.136167  0.126706  0.119189   \n",
      "22703  0.040570  0.338862  0.194787  0.172344  0.156756  0.145004  0.135657   \n",
      "\n",
      "         ema_45    ema_50   sma_vol       roc        cmo       ppo  \\\n",
      "0      0.156829  0.154781  4.110956 -4.930363  11.508362  2.970577   \n",
      "1      0.196209  0.190500  4.050205  1.032400  16.962188  3.053514   \n",
      "2      0.259821  0.248303 -0.546236  1.598866  24.774405  3.250285   \n",
      "3      0.160681  0.159050  0.473048 -1.897426  11.191402  3.361591   \n",
      "4      0.200571  0.195222 -1.599098  1.046878  16.490509  3.398493   \n",
      "...         ...       ...       ...       ...        ...       ...   \n",
      "22699  0.056265  0.056374  0.524302 -0.016742  22.175126  0.099986   \n",
      "22700  0.069835  0.068627  0.528854  0.364556  30.650131  0.028509   \n",
      "22701  0.079811  0.077686  0.528279  0.295815  36.696186 -0.035697   \n",
      "22702  0.112985  0.107735  0.688338  0.829649  49.921845  0.015009   \n",
      "22703  0.127963  0.121476  0.763927  0.449128  55.399286  0.149488   \n",
      "\n",
      "          linearreg           tsf  \n",
      "0        462.048771    464.956484  \n",
      "1        461.049000    463.534231  \n",
      "2        461.917400    464.243923  \n",
      "3        459.937457    461.772978  \n",
      "4        458.262343    459.570209  \n",
      "...             ...           ...  \n",
      "22699  51598.311329  51592.588824  \n",
      "22700  51699.704037  51708.675682  \n",
      "22701  51820.314744  51843.870802  \n",
      "22702  52033.590685  52080.616893  \n",
      "22703  52305.617668  52384.284569  \n",
      "\n",
      "[22704 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "crypto_ta_dataset[label_name] = crypto_ta_dataset[label_name].map(\n",
    "    {\"VLOW\":0,\"LOW\":1,\"VHIGH\":2,\"HIGH\":3,\"NEUTRAL\":4})\n",
    "\n",
    "# print(crypto_ta_dataset)\n",
    "# criamos duas variáveis, uma para os dados e outra para as labels (vamos precisar depois)\n",
    "features = crypto_ta_dataset.copy()\n",
    "labels = features.pop(label_name)\n",
    "# normalization dataset\n",
    "# features = tf.keras.utils.normalize(features, axis=-1, order=2)\n",
    "\n",
    "# imprime um resumo dos valores\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e4e1ad-dd5a-4572-854f-b72704d563ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns_plot = sns.pairplot(crypto_ta_dataset,hue=label_name,palette='Set2')\n",
    "# sns_plot.savefig(\"df4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5625609a-955f-4702-bb22-03847c4796c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir a estrutra a rede neuronal a utilizar\n",
    "# Neste caso temos duas camadas escondidas com 10 nós\n",
    "#     - Ativação do tipo relu (podem usar outras mas podem também escolher manter)\n",
    "#     - Dense significa que cada camada liga a todas as outras (recomendado)\n",
    "#     - Na primeira camada escondida indica-se, no parametro input_shape, que temos  entradas\n",
    "# A camada de saída deve ter o mesmo número de saídas que o número de classes\n",
    "#     - Por default a camada de saída devolve um logit para cada classe.\n",
    "#     - Um logit é um numero entre -Inf e +Inf que representa a classificação antes de ser normalizada\n",
    "#     - Podemos normalizar o resultado depois  para probalidades (usando a função softmax)\n",
    "#     - Podemos também indicar que esta camada usa logo a softmax mas não é recomendado\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu, input_shape=(15,)),  # input shape required\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec1e380-0d8f-415a-a760-5d3f9af6126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir as configurações do algoritmo\n",
    "# - Algoritmo usado para optimização (neste caso o SGD) com a learning rate \n",
    "#    - Podem decidir ajustar este parametro mas não é obrigatório\n",
    "# - Função que será usada para a minimização na procura\n",
    "#    - Neste caso usamos a SparseCategoricalCrossentropy\n",
    "#    - SparseCategorical é usada quanda trabalhamos com inteiros como target\n",
    "#    - from_logits=True indica que a saída da rede são logits\n",
    "#        - Se não usarmos este parametro temos de usar a softmax na saída da rede\n",
    "# - As metricas não são usadas para optimização, são usadas para dar output de resultados\n",
    "#    - Podem-se usar várias métricas ao mesmo tempo, dará vários valores de output\n",
    "#    - Neste caso estamos a usar a Accuracy (número )\n",
    "\n",
    "# definir as configurações do algoritmo\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721fbfe0-9a01-4086-bd70-ad00a517de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Criar o Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Percentages de teste e validação\n",
    "TEST_PERC = 0.1\n",
    "VALID_PERC = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4b64f9-686a-4016-90e7-665bc99e073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-2, shape=(), dtype=int64)\n",
      "22704 357 1750 441 1987 18169\n"
     ]
    }
   ],
   "source": [
    "# 2- Separar por classe (vai permitir garantir que cada conjunto tem X de cada classe)\n",
    "class0_dataset = dataset.filter(lambda x, y: y == 0)\n",
    "class1_dataset = dataset.filter(lambda x, y: y == 1)\n",
    "class2_dataset = dataset.filter(lambda x, y: y == 2)\n",
    "class3_dataset = dataset.filter(lambda x, y: y == 3)\n",
    "class4_dataset = dataset.filter(lambda x, y: y == 4)\n",
    "print(class0_dataset.cardinality())\n",
    "# quantidade de cada classe e total\n",
    "DATASIZE = dataset.cardinality().numpy()\n",
    "c0_size = len(list(class0_dataset))\n",
    "c1_size = len(list(class1_dataset))\n",
    "c2_size = len(list(class2_dataset))\n",
    "c3_size = len(list(class3_dataset))\n",
    "c4_size = len(list(class4_dataset))\n",
    "print(DATASIZE,c0_size,c1_size,c2_size,c3_size,c4_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38de53ad-9115-47ac-bb57-a4fe6311ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- Baralhar\n",
    "class0_dataset = class0_dataset.shuffle(DATASIZE)\n",
    "class1_dataset = class1_dataset.shuffle(DATASIZE)\n",
    "class2_dataset = class2_dataset.shuffle(DATASIZE)\n",
    "class3_dataset = class3_dataset.shuffle(DATASIZE)\n",
    "class4_dataset = class4_dataset.shuffle(DATASIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c93619e-26ff-4d07-ba2a-c7ea548b5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- Partir cada um\n",
    "# Primeiro retiramos o teste\n",
    "class0_test = class0_dataset.take(int(c0_size*TEST_PERC))\n",
    "# variável temporária para separar entre treino e validação\n",
    "# skip significa que vai ficar com o resto dos dados\n",
    "rest = class0_dataset.skip(int(c0_size*TEST_PERC))\n",
    "class0_validation = rest.take(int(c0_size*VALID_PERC))\n",
    "class0_train = rest.skip(int(c0_size*VALID_PERC))\n",
    "\n",
    "class1_test = class1_dataset.take(int(c1_size*TEST_PERC))\n",
    "rest = class1_dataset.skip(int(c1_size*TEST_PERC))\n",
    "class1_validation = rest.take(int(c1_size*VALID_PERC))\n",
    "class1_train = rest.skip(int(c1_size*VALID_PERC))\n",
    "\n",
    "class2_test = class2_dataset.take(int(c2_size*TEST_PERC))\n",
    "rest = class2_dataset.skip(int(c2_size*TEST_PERC))\n",
    "class2_validation = rest.take(int(c2_size*VALID_PERC))\n",
    "class2_train = rest.skip(int(c2_size*VALID_PERC))\n",
    "\n",
    "class3_test = class3_dataset.take(int(c3_size*TEST_PERC))\n",
    "rest = class3_dataset.skip(int(c3_size*TEST_PERC))\n",
    "class3_validation = rest.take(int(c3_size*VALID_PERC))\n",
    "class3_train = rest.skip(int(c3_size*VALID_PERC))\n",
    "\n",
    "class4_test = class4_dataset.take(int(c4_size*TEST_PERC))\n",
    "rest = class4_dataset.skip(int(c4_size*TEST_PERC))\n",
    "class4_validation = rest.take(int(c4_size*VALID_PERC))\n",
    "class4_train = rest.skip(int(c4_size*VALID_PERC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a303faf3-5b07-4fb1-9a13-bd289aacf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size =  18168\n",
      "Validation dataset size =  2268\n",
      "Test dataset size =  2268\n"
     ]
    }
   ],
   "source": [
    "#5- Juntar tudo novamente\n",
    "train_dataset = class0_train.concatenate(class1_train).concatenate(class2_train).concatenate(class3_train).concatenate(class4_train).shuffle(DATASIZE)\n",
    "test_dataset = class0_test.concatenate(class1_test).concatenate(class2_test).concatenate(class3_test).concatenate(class4_test).shuffle(DATASIZE)\n",
    "validation_dataset = class0_validation.concatenate(class1_validation).concatenate(class2_validation).concatenate(class3_validation).concatenate(class4_validation).shuffle(DATASIZE)\n",
    "\n",
    "#confirmar tamanhos\n",
    "print('Train dataset size = ', len(list(train_dataset)))\n",
    "print('Validation dataset size = ', len(list(validation_dataset)))\n",
    "print('Test dataset size = ', len(list(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999bb8c6-0113-4572-83d0-7a33aa9e4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6- Usar o dataset diretamente para treinar, validar e testar\n",
    "\n",
    "# Converter o conjunto de treino de novo para o formato inicial (DataFrame)\n",
    "feat,lab = map(list,zip(*list(train_dataset.as_numpy_iterator())))\n",
    "train_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "train_labels = pd.DataFrame(data=lab,columns=[label_name])\n",
    "\n",
    "feat,lab = map(list,zip(*list(validation_dataset.as_numpy_iterator())))\n",
    "valid_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "valid_labels = pd.DataFrame(data=lab,columns=[label_name])\n",
    "\n",
    "feat,lab = map(list,zip(*list(test_dataset.as_numpy_iterator())))\n",
    "test_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "test_labels = pd.DataFrame(data=lab,columns=[label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6d7b5c-9ad6-49cb-8a4f-54d640b7b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 12.3845 - sparse_categorical_accuracy: 0.7359 - val_loss: 1.1343 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 2/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.1051 - sparse_categorical_accuracy: 0.7963 - val_loss: 1.1551 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 3/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0951 - sparse_categorical_accuracy: 0.7979 - val_loss: 1.1115 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 4/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0802 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.1301 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 5/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0728 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0898 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 6/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0625 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.1017 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 7/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0566 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0746 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 8/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0489 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0826 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 9/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0422 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0692 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 10/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0348 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0622 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 11/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0286 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0640 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 12/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0229 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0510 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 13/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0171 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0345 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 14/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0105 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0334 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 15/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 1.0069 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0248 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 16/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9996 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0198 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 17/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9949 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0117 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 18/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9876 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0076 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 19/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9831 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0009 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 20/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9779 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.0017 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 21/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9722 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9921 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 22/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9677 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9930 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 23/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9614 - sparse_categorical_accuracy: 0.8001 - val_loss: 1.1546 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 24/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9569 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9775 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 25/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9525 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9717 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 26/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9475 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9919 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 27/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9434 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9635 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 28/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9380 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9602 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 29/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9324 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9514 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 30/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9304 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9502 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 31/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9248 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9446 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 32/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9207 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9412 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 33/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9167 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9320 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 34/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9120 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9280 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 35/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9081 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9253 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 36/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9047 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9247 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 37/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.9006 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9157 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 38/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8992 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9141 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 39/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8930 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9105 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 40/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8889 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9080 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 41/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8858 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9031 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 42/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.8822 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8962 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 43/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.8791 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8975 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 44/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8759 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8931 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 45/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.8716 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8854 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 46/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.8682 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8819 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 47/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8665 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8894 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 48/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8626 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8763 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 49/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8594 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8733 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 50/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8559 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8703 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 51/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8558 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8693 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 52/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8508 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8634 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 53/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8484 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8625 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 54/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8457 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8559 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 55/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8420 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8560 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 56/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8405 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8516 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 57/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8386 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8561 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 58/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8353 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8447 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 59/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8329 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8553 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 60/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8318 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8426 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 61/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8277 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8519 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 62/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8254 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8391 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 63/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8236 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8351 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 64/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8217 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8306 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 65/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8180 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8279 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 66/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8168 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8283 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 67/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8146 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8323 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 68/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8130 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8219 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 69/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8105 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8200 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 70/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8081 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8200 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 71/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8062 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8159 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 72/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8057 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8130 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 73/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8046 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8152 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 74/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8016 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8120 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 75/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.8004 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8097 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 76/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7983 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8068 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 77/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7975 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8039 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 78/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7956 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8063 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 79/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7945 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8084 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 80/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7923 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7995 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 81/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7918 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7990 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 82/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7901 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7984 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 83/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7889 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.8045 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 84/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7885 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7965 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 85/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7860 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7925 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 86/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7844 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7930 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 87/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7833 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7909 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 88/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7816 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7883 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 89/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7812 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7876 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 90/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7801 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7935 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 91/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7793 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7911 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 92/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7783 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7840 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 93/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7777 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7835 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 94/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7764 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7853 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 95/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.7764 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7927 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 96/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7751 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7793 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 97/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7734 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7785 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 98/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7726 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7817 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 99/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7719 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7772 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 100/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: 0.7709 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7761 - val_sparse_categorical_accuracy: 0.8007\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7fc85c58dc40>\n"
     ]
    }
   ],
   "source": [
    "# Correr o treino, indica as features as labels e o número de épocas\n",
    "history = model.fit(train_features, train_labels, epochs=100,validation_data=(valid_features,valid_labels))\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dad56cb3-f20b-4812-85ae-8a705e02b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 953us/step - loss: 0.7761 - sparse_categorical_accuracy: 0.8007\n",
      "Teste:\n",
      " [0.7761139273643494, 0.8007054924964905]\n"
     ]
    }
   ],
   "source": [
    "# Correr no conjunto teste (com o que foi treinado) e obter o resultado\n",
    "test = model.evaluate(test_features,test_labels)\n",
    "print(\"Teste:\\n\",test)\n",
    "loss,acc = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80949ab7-2e22-4895-9aa3-9db044730707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ver um plot dos resultados de treino e teste \n",
    "# coloquei também o valor do teste, mas esse é só um ponto no final\n",
    "# place a text box in upper left in axes coords\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(0.3, 0.90, \"Acc on test: %.2f\" % acc,  fontsize=14, transform=plt.axes().transAxes, \n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77804a-b7a7-4bec-bce5-a55aa45962dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
