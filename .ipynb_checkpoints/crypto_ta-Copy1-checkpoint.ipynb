{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9bd817-e8ed-43e7-8398-9e8a4b08d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a91643-49c2-437a-8887-2d14bede0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição da seed do python\n",
    "seed(1)\n",
    "# e seed do tensorflow\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f101b42a-2767-4501-a9c5-bc77b1a4e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição do ficheiro de dados (treino/validação)\n",
    "# symbol = 'ada'\n",
    "crypto_ta_dataset_fp = \"datasets/crypto_ta_btc_03.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0f0508-67cf-4501-bb3a-bca61e3e2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das classses\n",
    "# class_names = ['Very Low', 'Low', 'High', 'Very High']\n",
    "class_names = ['Low', 'High', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721b9bc1-dcb8-4e66-831c-4d970bf21a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sma_200     ema_8    ema_20    ema_25    ema_30    ema_35    ema_40  \\\n",
      "0  0.255202 -0.409322  0.096394  0.133747  0.149948  0.156290  0.157773   \n",
      "1  0.257581 -0.093549  0.186353  0.203982  0.208116  0.206254  0.201748   \n",
      "2  0.268577  0.281311  0.323255  0.313902  0.300544  0.286328  0.272576   \n",
      "3  0.251986 -0.207606  0.105288  0.137413  0.152578  0.159120  0.161111   \n",
      "4  0.253124  0.069138  0.195859  0.208523  0.211550  0.209772  0.205674   \n",
      "\n",
      "     ema_45    ema_50   sma_vol       roc        cmo      macd  macdsignal  \\\n",
      "0  0.156829  0.154781  4.110956 -4.930363  11.508362  9.974195    8.023714   \n",
      "1  0.196209  0.190500  4.050205  1.032400  16.962188  9.407627    8.300497   \n",
      "2  0.259821  0.248303 -0.546236  1.598866  24.774405  9.429688    8.526335   \n",
      "3  0.160681  0.159050  0.473048 -1.897426  11.191402  8.648446    8.550757   \n",
      "4  0.200571  0.195222 -1.599098  1.046878  16.490509  8.311856    8.502977   \n",
      "\n",
      "     macdhist       ppo   linearreg         tsf    trend  \n",
      "0  -44.011506  2.970577  462.048771  464.956484  NEUTRAL  \n",
      "1  -43.238067  3.053514  461.049000  463.534231  NEUTRAL  \n",
      "2  -18.405888  3.250285  461.917400  464.243923  NEUTRAL  \n",
      "3  -89.185964  3.361591  459.937457  461.772978  NEUTRAL  \n",
      "4 -295.642849  3.398493  458.262343  459.570209  NEUTRAL  \n",
      "Features: Index(['sma_200', 'ema_8', 'ema_20', 'ema_25', 'ema_30', 'ema_35', 'ema_40',\n",
      "       'ema_45', 'ema_50', 'sma_vol', 'roc', 'cmo', 'macd', 'macdsignal',\n",
      "       'macdhist', 'ppo', 'linearreg', 'tsf'],\n",
      "      dtype='object')\n",
      "Label: trend\n"
     ]
    }
   ],
   "source": [
    "# ler o ficheiro de dados, indicando o ficheiro e indicamos os nomes das colunas (que não estão no ficheiro)\n",
    "crypto_ta_dataset = pd.read_csv(crypto_ta_dataset_fp)\n",
    "# remover as colunas que nao interessam\n",
    "# crypto_ta_dataset.drop('ema_25', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('ema_30', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('ema_35', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('ema_40', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('ema_45', axis=1, inplace=True)\n",
    "# crypto_ta_dataset.drop('ema_50', axis=1, inplace=True)\n",
    "# imprime um as primeiras linhas dos dados\n",
    "print(crypto_ta_dataset.head())\n",
    "\n",
    "# colunas que são features e coluna que é a label (a ultima neste caso)\n",
    "feature_names = crypto_ta_dataset.columns[:-1]\n",
    "label_name = crypto_ta_dataset.columns[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6f7ad5-57df-4355-a950-5933cbe63e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sma_200     ema_8    ema_20    ema_25    ema_30    ema_35    ema_40  \\\n",
      "0      0.255202 -0.409322  0.096394  0.133747  0.149948  0.156290  0.157773   \n",
      "1      0.257581 -0.093549  0.186353  0.203982  0.208116  0.206254  0.201748   \n",
      "2      0.268577  0.281311  0.323255  0.313902  0.300544  0.286328  0.272576   \n",
      "3      0.251986 -0.207606  0.105288  0.137413  0.152578  0.159120  0.161111   \n",
      "4      0.253124  0.069138  0.195859  0.208523  0.211550  0.209772  0.205674   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "22702  0.039982  0.306922  0.167543  0.148832  0.136167  0.126706  0.119189   \n",
      "22703  0.040570  0.338862  0.194787  0.172344  0.156756  0.145004  0.135657   \n",
      "22704  0.036691  0.139075  0.122576  0.115657  0.110145  0.105460  0.101343   \n",
      "22705  0.037669  0.132032  0.121126  0.115023  0.109974  0.105578  0.101651   \n",
      "22706  0.039852  0.216552  0.158648  0.145874  0.136234  0.128484  0.121996   \n",
      "\n",
      "         ema_45    ema_50   sma_vol       roc        cmo        macd  \\\n",
      "0      0.156829  0.154781  4.110956 -4.930363  11.508362    9.974195   \n",
      "1      0.196209  0.190500  4.050205  1.032400  16.962188    9.407627   \n",
      "2      0.259821  0.248303 -0.546236  1.598866  24.774405    9.429688   \n",
      "3      0.160681  0.159050  0.473048 -1.897426  11.191402    8.648446   \n",
      "4      0.200571  0.195222 -1.599098  1.046878  16.490509    8.311856   \n",
      "...         ...       ...       ...       ...        ...         ...   \n",
      "22702  0.112985  0.107735  0.688338  0.829649  49.921845  280.537002   \n",
      "22703  0.127963  0.121476  0.763927  0.449128  55.399286  331.119421   \n",
      "22704  0.097672  0.094374  0.755054 -0.549677  35.742456  343.850265   \n",
      "22705  0.098110  0.094902  0.751405  0.107533  37.401484  354.405275   \n",
      "22706  0.116432  0.111584  0.789037  0.510625  44.709381  380.023774   \n",
      "\n",
      "       macdsignal    macdhist       ppo     linearreg           tsf  \n",
      "0        8.023714  -44.011506  2.970577    462.048771    464.956484  \n",
      "1        8.300497  -43.238067  3.053514    461.049000    463.534231  \n",
      "2        8.526335  -18.405888  3.250285    461.917400    464.243923  \n",
      "3        8.550757  -89.185964  3.361591    459.937457    461.772978  \n",
      "4        8.502977 -295.642849  3.398493    458.262343    459.570209  \n",
      "...           ...         ...       ...           ...           ...  \n",
      "22702  253.032922 -368.273792  0.015009  52033.590685  52080.616893  \n",
      "22703  268.650222  127.127029  0.149488  52305.617668  52384.284569  \n",
      "22704  283.690231   -3.696485  0.280139  52470.748041  52567.349068  \n",
      "22705  297.833240   -5.964090  0.389547  52575.941006  52676.403142  \n",
      "22706  314.271347   16.227791  0.488742  52709.947544  52815.135016  \n",
      "\n",
      "[22707 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "crypto_ta_dataset[label_name] = crypto_ta_dataset[label_name].map(\n",
    "    {\"LOW\":0,\"HIGH\":1,\"NEUTRAL\":2})\n",
    "\n",
    "# print(crypto_ta_dataset)\n",
    "# criamos duas variáveis, uma para os dados e outra para as labels (vamos precisar depois)\n",
    "features = crypto_ta_dataset.copy()\n",
    "labels = features.pop(label_name)\n",
    "# normalization dataset\n",
    "# features = tf.keras.utils.normalize(features, axis=-1, order=2)\n",
    "\n",
    "# imprime um resumo dos valores\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e4e1ad-dd5a-4572-854f-b72704d563ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns_plot = sns.pairplot(crypto_ta_dataset,hue=label_name,palette='Set2')\n",
    "# sns_plot.savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5625609a-955f-4702-bb22-03847c4796c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir a estrutra a rede neuronal a utilizar\n",
    "# Neste caso temos duas camadas escondidas com 10 nós\n",
    "#     - Ativação do tipo relu (podem usar outras mas podem também escolher manter)\n",
    "#     - Dense significa que cada camada liga a todas as outras (recomendado)\n",
    "#     - Na primeira camada escondida indica-se, no parametro input_shape, que temos  entradas\n",
    "# A camada de saída deve ter o mesmo número de saídas que o número de classes\n",
    "#     - Por default a camada de saída devolve um logit para cada classe.\n",
    "#     - Um logit é um numero entre -Inf e +Inf que representa a classificação antes de ser normalizada\n",
    "#     - Podemos normalizar o resultado depois  para probalidades (usando a função softmax)\n",
    "#     - Podemos também indicar que esta camada usa logo a softmax mas não é recomendado\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu, input_shape=(18,)),  # input shape required\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec1e380-0d8f-415a-a760-5d3f9af6126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir as configurações do algoritmo\n",
    "# - Algoritmo usado para optimização (neste caso o SGD) com a learning rate \n",
    "#    - Podem decidir ajustar este parametro mas não é obrigatório\n",
    "# - Função que será usada para a minimização na procura\n",
    "#    - Neste caso usamos a SparseCategoricalCrossentropy\n",
    "#    - SparseCategorical é usada quanda trabalhamos com inteiros como target\n",
    "#    - from_logits=True indica que a saída da rede são logits\n",
    "#        - Se não usarmos este parametro temos de usar a softmax na saída da rede\n",
    "# - As metricas não são usadas para optimização, são usadas para dar output de resultados\n",
    "#    - Podem-se usar várias métricas ao mesmo tempo, dará vários valores de output\n",
    "#    - Neste caso estamos a usar a Accuracy (número )\n",
    "\n",
    "# definir as configurações do algoritmo\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721fbfe0-9a01-4086-bd70-ad00a517de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Criar o Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Percentages de teste e validação\n",
    "TEST_PERC = 0.1\n",
    "VALID_PERC = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4b64f9-686a-4016-90e7-665bc99e073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf.Tensor(-2, shape=(), dtype=int64)\n",
      "22707 2107 2428 18172\n"
     ]
    }
   ],
   "source": [
    "# 2- Separar por classe (vai permitir garantir que cada conjunto tem X de cada classe)\n",
    "class0_dataset = dataset.filter(lambda x, y: y == 0)\n",
    "class1_dataset = dataset.filter(lambda x, y: y == 1)\n",
    "class2_dataset = dataset.filter(lambda x, y: y == 2)\n",
    "# class3_dataset = dataset.filter(lambda x, y: y == 3)\n",
    "print()\n",
    "print(class0_dataset.cardinality())\n",
    "# quantidade de cada classe e total\n",
    "DATASIZE = dataset.cardinality().numpy()\n",
    "c0_size = len(list(class0_dataset))\n",
    "c1_size = len(list(class1_dataset))\n",
    "c2_size = len(list(class2_dataset))\n",
    "# c3_size = len(list(class3_dataset))\n",
    "print(DATASIZE,c0_size,c1_size,c2_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38de53ad-9115-47ac-bb57-a4fe6311ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- Baralhar\n",
    "class0_dataset = class0_dataset.shuffle(DATASIZE)\n",
    "class1_dataset = class1_dataset.shuffle(DATASIZE)\n",
    "class2_dataset = class2_dataset.shuffle(DATASIZE)\n",
    "# class3_dataset = class3_dataset.shuffle(DATASIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c93619e-26ff-4d07-ba2a-c7ea548b5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- Partir cada um\n",
    "# Primeiro retiramos o teste\n",
    "class0_test = class0_dataset.take(int(c0_size*TEST_PERC))\n",
    "# variável temporária para separar entre treino e validação\n",
    "# skip significa que vai ficar com o resto dos dados\n",
    "rest = class0_dataset.skip(int(c0_size*TEST_PERC))\n",
    "class0_validation = rest.take(int(c0_size*VALID_PERC))\n",
    "class0_train = rest.skip(int(c0_size*VALID_PERC))\n",
    "\n",
    "class1_test = class1_dataset.take(int(c1_size*TEST_PERC))\n",
    "rest = class1_dataset.skip(int(c1_size*TEST_PERC))\n",
    "class1_validation = rest.take(int(c1_size*VALID_PERC))\n",
    "class1_train = rest.skip(int(c1_size*VALID_PERC))\n",
    "\n",
    "class2_test = class2_dataset.take(int(c2_size*TEST_PERC))\n",
    "rest = class2_dataset.skip(int(c2_size*TEST_PERC))\n",
    "class2_validation = rest.take(int(c2_size*VALID_PERC))\n",
    "class2_train = rest.skip(int(c2_size*VALID_PERC))\n",
    "\n",
    "# class3_test = class3_dataset.take(int(c3_size*TEST_PERC))\n",
    "# rest = class3_dataset.skip(int(c3_size*TEST_PERC))\n",
    "# class3_validation = rest.take(int(c3_size*VALID_PERC))\n",
    "# class3_train = rest.skip(int(c3_size*VALID_PERC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a303faf3-5b07-4fb1-9a13-bd289aacf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size =  18169\n",
      "Validation dataset size =  2269\n",
      "Test dataset size =  2269\n"
     ]
    }
   ],
   "source": [
    "#5- Juntar tudo novamente\n",
    "train_dataset = class0_train.concatenate(class1_train).concatenate(class2_train).shuffle(DATASIZE)\n",
    "test_dataset = class0_test.concatenate(class1_test).concatenate(class2_test).shuffle(DATASIZE)\n",
    "validation_dataset = class0_validation.concatenate(class1_validation).concatenate(class2_validation).shuffle(DATASIZE)\n",
    "\n",
    "#confirmar tamanhos\n",
    "print('Train dataset size = ', len(list(train_dataset)))\n",
    "print('Validation dataset size = ', len(list(validation_dataset)))\n",
    "print('Test dataset size = ', len(list(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999bb8c6-0113-4572-83d0-7a33aa9e4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6- Usar o dataset diretamente para treinar, validar e testar\n",
    "\n",
    "# Converter o conjunto de treino de novo para o formato inicial (DataFrame)\n",
    "feat,lab = map(list,zip(*list(train_dataset.as_numpy_iterator())))\n",
    "train_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "train_labels = pd.DataFrame(data=lab,columns=[label_name])\n",
    "\n",
    "feat,lab = map(list,zip(*list(validation_dataset.as_numpy_iterator())))\n",
    "valid_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "valid_labels = pd.DataFrame(data=lab,columns=[label_name])\n",
    "\n",
    "feat,lab = map(list,zip(*list(test_dataset.as_numpy_iterator())))\n",
    "test_features= pd.DataFrame(data=feat,columns=feature_names)\n",
    "test_labels = pd.DataFrame(data=lab,columns=[label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6d7b5c-9ad6-49cb-8a4f-54d640b7b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 11.2148 - sparse_categorical_accuracy: 0.7371 - val_loss: 6.7817 - val_sparse_categorical_accuracy: 0.8008\n",
      "Epoch 2/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 2.4313 - sparse_categorical_accuracy: 0.7610 - val_loss: 1.0076 - val_sparse_categorical_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.1638 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 4/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 5/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 6/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 7/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 8/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 9/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 10/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 11/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 12/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 13/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 14/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 15/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 16/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 17/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 18/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 19/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 20/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 21/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 22/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 23/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 24/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 25/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 26/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 27/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 28/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 29/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 30/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 31/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 32/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 33/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 34/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 35/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 36/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 37/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 38/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 39/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 40/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 41/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 42/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 43/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 44/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 45/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 46/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 47/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 48/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 49/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 50/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 51/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 52/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 53/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 54/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 55/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 56/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 57/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 58/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 59/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 60/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 61/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 62/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 63/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 64/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 65/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 66/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 67/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 68/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 69/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 70/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 71/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 72/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 73/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 74/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 75/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 76/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 77/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 78/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 79/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 80/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 81/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 82/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 83/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 84/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 85/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 86/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 87/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 88/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 89/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 90/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 91/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 92/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 93/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 94/100\n",
      "568/568 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 95/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 96/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 97/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 98/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 99/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "Epoch 100/100\n",
      "568/568 [==============================] - 1s 1ms/step - loss: nan - sparse_categorical_accuracy: 0.0929 - val_loss: nan - val_sparse_categorical_accuracy: 0.0926\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7f54c4106310>\n"
     ]
    }
   ],
   "source": [
    "# Correr o treino, indica as features as labels e o número de épocas\n",
    "history = model.fit(train_features, train_labels, epochs=100,validation_data=(valid_features,valid_labels))\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dad56cb3-f20b-4812-85ae-8a705e02b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 872us/step - loss: nan - sparse_categorical_accuracy: 0.0926\n",
      "Teste:\n",
      " [nan, 0.09255178272724152]\n"
     ]
    }
   ],
   "source": [
    "# Correr no conjunto teste (com o que foi treinado) e obter o resultado\n",
    "test = model.evaluate(test_features,test_labels)\n",
    "print(\"Teste:\\n\",test)\n",
    "loss,acc = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80949ab7-2e22-4895-9aa3-9db044730707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ver um plot dos resultados de treino e teste \n",
    "# coloquei também o valor do teste, mas esse é só um ponto no final\n",
    "# place a text box in upper left in axes coords\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(0.3, 0.90, \"Acc on test: %.2f\" % acc,  fontsize=14, transform=plt.axes().transAxes, \n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77804a-b7a7-4bec-bce5-a55aa45962dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
